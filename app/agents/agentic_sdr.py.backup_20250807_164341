"""
AGENTIC SDR - Agente Principal Conversacional Ultra-Humanizado
Com an√°lise contextual inteligente das √∫ltimas 100 mensagens
"""

import asyncio
import json
import random
import re
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime, timedelta
from enum import Enum
import base64

from agno.agent import Agent
from agno.models.google import Gemini
# OpenAI via requests - contorna problemas do SDK
try:
    import requests
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

from app.utils.time_utils import get_period_of_day


class SimpleOpenAIWrapper:
    """
    Wrapper OpenAI usando requests diretos para evitar problemas do SDK
    """
    def __init__(self, api_key, id="o3-mini", max_tokens=4000, temperature=0.7):
        if not OPENAI_AVAILABLE:
            raise ImportError("requests n√£o dispon√≠vel")
            
        import requests
        self.api_key = api_key
        self.model_id = id
        self.max_tokens = max_tokens
        self.temperature = temperature
        self.base_url = "https://api.openai.com/v1"
        self.session = requests.Session()
        self.session.headers.update({
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        })
    
    def run(self, message, **kwargs):
        """Interface compat√≠vel com AGNO usando requests diretos"""
        try:
            payload = {
                "model": self.model_id,
                "messages": [{"role": "user", "content": str(message)}],
                "max_completion_tokens": self.max_tokens  # o3-mini usa max_completion_tokens, sem temperature
            }
            
            response = self.session.post(
                f"{self.base_url}/chat/completions",
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                return data["choices"][0]["message"]["content"]
            else:
                raise Exception(f"API Error {response.status_code}: {response.text}")
                
        except Exception as e:
            raise Exception(f"OpenAI o3-mini falhou: {e}")
    
    def __str__(self):
        return f"SimpleOpenAI({self.model_id})"
from agno.memory import AgentMemory
from agno.knowledge import AgentKnowledge
from agno.tools import tool
from loguru import logger
from app.utils.logger import emoji_logger
from app.utils.optional_storage import OptionalStorage
from app.utils.agno_media_detection import agno_media_detector
from app.utils.retry_handler import async_retry, GEMINI_RETRY_CONFIG, OPENAI_RETRY_CONFIG

from app.config import settings
from app.integrations.supabase_client import supabase_client
from app.teams.sdr_team import SDRTeam

# Servi√ßos REMOVIDOS - substitu√≠dos por fun√ß√µes simples inline
# from app.services.agno_context_agent import format_context_with_agno
# from app.services.document_processor_enhanced import process_document_enhanced
# KnowledgeService - Substitui KnowledgeAgent com implementa√ß√£o mais simples
from app.services.knowledge_service import knowledge_service


class IntelligentModelFallback:
    """
    Wrapper inteligente para gerenciar fallback autom√°tico entre modelos
    Detecta erros Gemini e automaticamente usa OpenAI o3-mini
    """
    
    def __init__(self, settings):
        self.settings = settings
        self.primary_model = None
        self.fallback_model = None
        self.current_model = None
        # Importar o detector de m√≠dia como atributo da classe
        self.agno_media_detector = agno_media_detector
        self.fallback_active = False
        
        # Configura√ß√µes de retry para Gemini
        self.max_retry_attempts = getattr(settings, 'gemini_retry_attempts', 2)  # 2 tentativas de retry
        self.retry_delay = getattr(settings, 'gemini_retry_delay', 5.0)  # 5 segundos entre tentativas
        
        # Armazenar instructions do agente principal
        self._agent_instructions = None
        
        self._initialize_models()
    
    def set_agent_instructions(self, instructions):
        """Define as instructions do agente principal para usar nos temp_agents"""
        self._agent_instructions = instructions
    
    @property
    def id(self):
        """Exp√µe o ID do modelo atual para compatibilidade com agno.agent.Agent"""
        if self.current_model:
            return self.current_model.id
        return "unknown_model"
    
    @property
    def provider(self):
        """Exp√µe o provider do modelo atual para compatibilidade com agno.agent.Agent"""
        if self.current_model and hasattr(self.current_model, 'provider'):
            return self.current_model.provider
        # Inferir provider do ID do modelo
        if self.current_model and hasattr(self.current_model, 'id'):
            model_id = self.current_model.id
            if 'gemini' in model_id.lower():
                return 'google'
            elif 'gpt' in model_id.lower() or 'o3' in model_id.lower():
                return 'openai'
        return "unknown"
    
    def __getattr__(self, name):
        """
        Delega qualquer atributo/m√©todo n√£o encontrado para o modelo atual.
        Isso garante compatibilidade total com agno.agent.Agent.
        """
        if name.startswith('_'):  # Evitar recurs√£o infinita com atributos privados
            raise AttributeError(f"'{self.__class__.__name__}' object has no attribute '{name}'")
        
        if self.current_model is None:
            raise AttributeError(f"No current model available to delegate '{name}'")
        
        # Tentar obter o atributo/m√©todo do modelo atual
        try:
            return getattr(self.current_model, name)
        except AttributeError:
            # Se o modelo atual n√£o tem o atributo, retornar um valor padr√£o ou fun√ß√£o vazia
            if name == 'get_instructions_for_model':
                # Retornar fun√ß√£o vazia que retorna string vazia
                return lambda: ""
            raise AttributeError(f"'{self.__class__.__name__}' object and current model have no attribute '{name}'")
    
    def _initialize_models(self):
        """Inicializa os modelos prim√°rio e fallback"""
        try:
            # Modelo prim√°rio (Gemini)
            if "gemini" in self.settings.primary_ai_model.lower():
                self.primary_model = Gemini(
                    id=self.settings.primary_ai_model,
                    api_key=self.settings.google_api_key,
                    temperature=self.settings.ai_temperature,
                    max_output_tokens=self.settings.ai_max_tokens
                )
                emoji_logger.system_ready("Modelo prim√°rio Gemini configurado", 
                                         model=self.settings.primary_ai_model)
            
            # Modelo fallback (OpenAI o3-mini)  
            if self.settings.enable_model_fallback and self.settings.openai_api_key and OPENAI_AVAILABLE:
                try:
                    # Usar wrapper customizado OpenAI (compat√≠vel)
                    self.fallback_model = SimpleOpenAIWrapper(
                        api_key=self.settings.openai_api_key,
                        id="o3-mini",
                        max_tokens=self.settings.ai_max_tokens,
                        temperature=self.settings.ai_temperature
                    )
                    emoji_logger.system_ready("Modelo fallback OpenAI o3-mini configurado")
                        
                except Exception as e:
                    emoji_logger.system_warning(f"Falha ao configurar OpenAI o3-mini fallback: {e}")
                    self.fallback_model = None
            else:
                if not OPENAI_AVAILABLE:
                    emoji_logger.system_warning("OpenAI n√£o dispon√≠vel - fallback desabilitado")
                elif not self.settings.openai_api_key:
                    emoji_logger.system_warning("OPENAI_API_KEY n√£o configurada - fallback desabilitado")
                else:
                    emoji_logger.system_warning("Fallback desabilitado por configura√ß√£o")
                self.fallback_model = None
            
            # Define modelo atual
            self.current_model = self.primary_model
            
        except Exception as e:
            emoji_logger.system_error("Model Init", f"Erro na inicializa√ß√£o de modelos: {e}")
            raise
    
    def _is_gemini_error(self, error) -> bool:
        """Detecta se √© um erro que requer fallback"""
        error_str = str(error).lower()
        
        # Erros que requerem fallback
        fallback_triggers = [
            "500 internal",
            "503 service unavailable", 
            "502 bad gateway",
            "timeout",
            "connection error",
            "server error",
            "internal error has occurred"
        ]
        
        return any(trigger in error_str for trigger in fallback_triggers)
    
    def _should_retry_with_fallback(self, error) -> bool:
        """Determina se deve tentar fallback"""
        return (
            not self.fallback_active and  # N√£o estamos j√° usando fallback
            self.fallback_model is not None and  # Temos modelo fallback
            self._is_gemini_error(error)  # √â um erro que requer fallback
        )
    
    @async_retry(GEMINI_RETRY_CONFIG)
    async def _gemini_call_with_retry(self, message: str, **kwargs):
        """Chamada Gemini com retry autom√°tico via decorador"""
        if self.primary_model:
            # SOLU√á√ÉO DEFINITIVA: Usar arun() para async ou asyncio.to_thread para sync
            from agno.agent import Agent
            import asyncio
            
            # Usar instructions do agente principal se dispon√≠vel, sen√£o usar padr√£o
            instructions = self._agent_instructions or kwargs.pop('instructions', 'Voc√™ √© Helen, uma vendedora especializada em energia solar da SolarPrime. Responda de forma natural, emp√°tica e focada em ajudar o cliente.')
            
            temp_agent = Agent(
                model=self.primary_model,
                markdown=True,
                show_tool_calls=False,
                instructions=instructions
            )
            
            # Verificar se tem arun (async) ou usar run em thread
            if hasattr(temp_agent, 'arun'):
                response = await temp_agent.arun(message, **kwargs)
            else:
                # Executar run() s√≠ncrono em thread para n√£o bloquear
                response = await asyncio.to_thread(temp_agent.run, message, **kwargs)
            
            return response
            
        raise Exception("Modelo prim√°rio Gemini n√£o dispon√≠vel")
    
    @async_retry(OPENAI_RETRY_CONFIG)
    async def _openai_call_with_retry(self, message: str, **kwargs):
        """Chamada OpenAI com retry autom√°tico via decorador"""
        if self.fallback_model:
            # OpenAI wrapper tem run() implementado
            return self.fallback_model.run(message, **kwargs)
        raise Exception("Modelo fallback OpenAI n√£o dispon√≠vel")
    
    async def _retry_with_backoff(self, message: str, **kwargs):
        """
        Tenta executar o Gemini com retry e backoff
        Retorna a resposta ou None se todas as tentativas falharem
        """
        import asyncio
        from agno.agent import Agent
        
        last_error = None
        
        for attempt in range(self.max_retry_attempts):
            try:
                emoji_logger.system_info(f"üîÑ Retry Gemini - Tentativa {attempt + 1}/{self.max_retry_attempts}")
                
                # O Gemini no AGNO precisa ser usado atrav√©s de um Agent
                # Usar instructions do agente principal se dispon√≠vel, sen√£o usar padr√£o
                instructions = self._agent_instructions or kwargs.pop('instructions', 'Voc√™ √© Helen, uma vendedora especializada em energia solar da SolarPrime. Responda de forma natural, emp√°tica e focada em ajudar o cliente.')
                
                temp_agent = Agent(
                    model=self.primary_model,
                    markdown=True,
                    show_tool_calls=False,
                    instructions=instructions
                )
                
                # Usar arun se dispon√≠vel, sen√£o run em thread
                if hasattr(temp_agent, 'arun'):
                    response = await temp_agent.arun(message, **kwargs)
                else:
                    response = await asyncio.to_thread(temp_agent.run, message, **kwargs)
                
                if attempt > 0:
                    emoji_logger.system_ready(f"‚úÖ Gemini recuperado ap√≥s {attempt + 1} tentativa(s)")
                
                return response
                
            except Exception as e:
                last_error = e
                error_str = str(e).lower()
                
                # S√≥ faz retry se for erro tempor√°rio do Gemini
                if self._is_gemini_error(e):
                    if attempt < self.max_retry_attempts - 1:
                        emoji_logger.system_warning(
                            f"‚ö†Ô∏è Erro Gemini: {e}. Aguardando {self.retry_delay}s antes da pr√≥xima tentativa..."
                        )
                        await asyncio.sleep(self.retry_delay)
                    else:
                        emoji_logger.system_warning(
                            f"‚ùå Gemini falhou ap√≥s {self.max_retry_attempts} tentativas"
                        )
                else:
                    # Se n√£o for erro tempor√°rio, n√£o faz retry
                    emoji_logger.system_warning(f"‚ùå Erro Gemini n√£o recuper√°vel: {e}")
                    raise e
        
        # Se chegou aqui, todas as tentativas falharam
        return None
    
    async def run(self, message: str, **kwargs):
        """
        Executa o modelo com retry inteligente e fallback
        Fluxo: Gemini ‚Üí Retry (se erro 500/503) ‚Üí Fallback OpenAI (se retry falhar)
        """
        # Se j√° estamos usando fallback, usa direto com retry
        if self.fallback_active and self.current_model == self.fallback_model:
            try:
                response = await self._openai_call_with_retry(message, **kwargs)
                emoji_logger.system_info("üìç Usando fallback OpenAI o3-mini com retry")
                return response
            except Exception as e:
                emoji_logger.system_error("Fallback OpenAI falhou ap√≥s m√∫ltiplas tentativas", error=str(e))
                raise e
        
        # Tenta com modelo prim√°rio (Gemini) usando retry autom√°tico
        try:
            if self.primary_model:
                response = await self._gemini_call_with_retry(message, **kwargs)
                
                # Se estava usando fallback e Gemini funcionou, desativa fallback
                if self.fallback_active:
                    emoji_logger.system_ready("‚úÖ Gemini recuperado, desativando fallback")
                    self.fallback_active = False
                    self.current_model = self.primary_model
                
                return response
                
        except Exception as e:
            emoji_logger.system_warning(f"‚ö†Ô∏è Gemini falhou ap√≥s m√∫ltiplas tentativas: {e}")
            
            # Se temos fallback, ativa OpenAI com retry
            if self.fallback_model is not None:
                emoji_logger.system_warning("üîÑ Ativando fallback OpenAI o3-mini com retry...")
                
                try:
                    self.current_model = self.fallback_model
                    self.fallback_active = True
                    
                    response = await self._openai_call_with_retry(message, **kwargs)
                    emoji_logger.system_ready("‚úÖ Fallback OpenAI o3-mini ativado com sucesso")
                    return response
                        
                except Exception as fallback_error:
                    emoji_logger.system_error("Fallback OpenAI tamb√©m falhou", error=str(fallback_error))
                    # Volta para modelo prim√°rio para pr√≥xima tentativa
                    self.current_model = self.primary_model
                    self.fallback_active = False
                    raise fallback_error
            else:
                # Erro n√£o recuper√°vel, n√£o faz retry
                emoji_logger.system_error("Erro n√£o recuper√°vel no Gemini", error=str(e))
                raise e
    
    def reset_to_primary(self):
        """For√ßa volta ao modelo prim√°rio"""
        if self.primary_model:
            self.current_model = self.primary_model
            self.fallback_active = False
            emoji_logger.system_info("Modelo resetado para prim√°rio (Gemini)")
    
    def get_current_model_info(self) -> dict:
        """Retorna informa√ß√µes do modelo atual"""
        return {
            "current_model": self.current_model.__class__.__name__ if self.current_model else None,
            "fallback_active": self.fallback_active,
            "has_fallback": self.fallback_model is not None
        }
    
    # Alias para compatibilidade com AGNO Agent
    async def arun(self, message: str, **kwargs):
        """Alias para run() - mant√©m compatibilidade com AGNO Agent que espera arun()"""
        return await self.run(message, **kwargs)


class ConversationContext(Enum):
    """Contextos de conversa detectados"""
    INITIAL_CONTACT = "initial_contact"
    QUALIFICATION_NEEDED = "qualification_needed"
    HIGH_VALUE_LEAD = "high_value_lead"
    SCHEDULING_READY = "scheduling_ready"
    OBJECTION_HANDLING = "objection_handling"
    TECHNICAL_QUESTIONS = "technical_questions"
    FOLLOW_UP_REQUIRED = "follow_up_required"
    COMPLEX_NEGOTIATION = "complex_negotiation"
    DOCUMENT_ANALYSIS = "document_analysis"
    CRM_UPDATE_NEEDED = "crm_update_needed"


class EmotionalState(Enum):
    """Estados emocionais do AGENTIC SDR - Alinhados com banco de dados"""
    ENTUSIASMADA = "ENTUSIASMADA"
    CURIOSA = "CURIOSA"
    CONFIANTE = "CONFIANTE"
    DUVIDOSA = "DUVIDOSA"
    NEUTRA = "NEUTRA"


class AgenticSDR:
    """
    Agente Principal AGENTIC SDR Ultra-Humanizado
    
    Caracter√≠sticas:
    - An√°lise contextual inteligente das √∫ltimas 100 mensagens
    - Personalidade ultra-humanizada com estados emocionais
    - Multimodal (imagens, √°udio, documentos)
    - Reasoning para casos complexos
    - Memory persistente com pgvector
    - Decision engine inteligente para SDR Team
    """
    
    def __init__(self):
        """Inicializa o AGENTIC SDR com todas as capacidades"""
        self.is_initialized = False
        
        # Importar o detector de m√≠dia como atributo da classe
        self.agno_media_detector = agno_media_detector
        
        # Armazenar refer√™ncia ao settings
        self.settings = settings
        
        # Configura√ß√µes de funcionalidades baseadas no .env
        self.context_analysis_enabled = settings.enable_context_analysis
        self.reasoning_enabled = settings.agno_reasoning_enabled
        self.multimodal_enabled = settings.enable_multimodal_analysis
        self.knowledge_search_enabled = settings.enable_knowledge_base
        
        # Cache removido - sempre buscar hist√≥rico atualizado do Supabase
        self.sentiment_analysis_enabled = settings.enable_sentiment_analysis
        self.emotional_triggers_enabled = settings.enable_emotional_triggers
        self.lead_scoring_enabled = settings.enable_lead_scoring
        self.emoji_usage_enabled = settings.enable_emoji_usage
        
        # REMOVIDO: Estado emocional como atributo de inst√¢ncia
        # Agora o estado √© gerenciado por conversa no banco de dados
        
        # Configura√ß√£o do PostgreSQL/Supabase para storage com fallback
        # Storage persistente com fallback para mem√≥ria se PostgreSQL n√£o dispon√≠vel
        self.storage = OptionalStorage(
            table_name="agentic_sdr_sessions",  # Nome da tabela para sess√µes do agente
            db_url=settings.get_postgres_url(),  # URL j√° inclui autentica√ß√£o
            schema="public",  # Schema do Supabase
            auto_upgrade_schema=True  # Auto-atualiza schema se necess√°rio
        )
        
        # Setup models BEFORE Memory (needed for fallback)
        self._setup_models()
        
        # Memory v2 - SOLU√á√ÉO DEFINITIVA (conforme ANALISE_ERRO_AGENTMEMORY.md)
        # AgentMemory agora √© apenas para mem√≥ria de trabalho (RAM), sem db
        # O storage √© passado diretamente para o Agent, n√£o para AgentMemory
        try:
            # CORRE√á√ÉO: AgentMemory sem par√¢metro db (arquitetura nova do AGNO)
            self.memory = AgentMemory(
                create_user_memories=True,
                create_session_summary=True
            )
            emoji_logger.system_ready("Memory", status="configurada (in-memory)")
        except Exception as e:
            emoji_logger.system_info(f"Memory fallback: {str(e)[:100]}...")
            # Se AgentMemory falhar completamente, usar None
            # O Agent da AGNO aceita memory=None
            self.memory = None
            emoji_logger.system_info("üíæ Memory: Desabilitado (Agent funcionar√° sem mem√≥ria)")
        
        # Knowledge base SEM PostgreSQL - usando apenas dados locais
        # Sistema funciona perfeitamente sem vector database PostgreSQL
        try:
            # AgentKnowledge sem vector_db (usa conhecimento local)
            self.knowledge = AgentKnowledge(
                num_documents=10  # Busca em conhecimento local/mem√≥ria
            )
            self.vector_db = None  # N√£o precisamos de PostgreSQL
            emoji_logger.system_ready("Knowledge", status="local ativo")
        except Exception as e:
            emoji_logger.system_info(f"Knowledge desabilitado: {str(e)[:40]}...")
            self.vector_db = None
            self.knowledge = None
        
        # SDR Team para tarefas especializadas
        self.sdr_team = None
        
        # Context analyzer tools - apenas habilitar as ferramentas configuradas
        self.tools = []
        
        # Adicionar ferramentas baseadas nas configura√ß√µes
        if self.context_analysis_enabled:
            self.tools.append(self.analyze_conversation_context)
            self.tools.append(self.get_last_100_messages)
        
        if self.emotional_triggers_enabled:
            self.tools.append(self.detect_emotional_triggers)
        
        # Sempre incluir decis√£o do SDR Team
        self.tools.append(self.should_call_sdr_team)
        
        if self.multimodal_enabled:
            self.tools.append(self.process_multimodal_content)
        
        if self.knowledge_search_enabled:
            self.tools.append(self.search_knowledge_base)
            self.tools.append(self.analyze_energy_bill)
        
        tool_names = []
        for t in self.tools:
            if hasattr(t, '__name__'):
                tool_names.append(t.__name__)
            elif hasattr(t, 'name'):
                tool_names.append(t.name)
            else:
                tool_names.append(str(t))
        emoji_logger.agentic_thinking(f"Tools habilitadas: {len(self.tools)}", 
                                      tools=tool_names)
        
        # Criar o agente principal
        self._create_agentic_agent()
        
        emoji_logger.agentic_start("Sistema inicializado com sucesso", 
                                   context_enabled=self.context_analysis_enabled,
                                   reasoning_enabled=self.reasoning_enabled,
                                   multimodal_enabled=self.multimodal_enabled)
    
    def _setup_models(self):
        """Configura modelos com fallback inteligente para OpenAI o3-mini"""
        try:
            # Usar novo sistema de fallback inteligente
            self.intelligent_model = IntelligentModelFallback(settings)
            
            # Para compatibilidade, manter refer√™ncia self.model
            self.model = self.intelligent_model.current_model
            
            # Modelo de reasoning - Gemini 2.0 Flash Thinking (se habilitado)
            if self.reasoning_enabled and settings.google_api_key:
                try:
                    self.reasoning_model = Gemini(
                        id="gemini-2.0-flash-thinking-exp-01-21",
                        api_key=settings.google_api_key,
                        thinking_budget=8192,
                        include_thoughts=False  # ‚úÖ CORRIGIDO: N√£o vazar racioc√≠nio interno para usu√°rio
                    )
                    emoji_logger.system_ready("Modelo reasoning configurado", model="gemini-2.0-flash-thinking")
                except Exception as e:
                    emoji_logger.system_warning(f"Reasoning model falhou, usando modelo principal: {e}")
                    self.reasoning_model = self.intelligent_model.current_model
            else:
                self.reasoning_model = self.intelligent_model.current_model
            
            # Log status final
            model_info = self.intelligent_model.get_current_model_info()
            emoji_logger.system_ready("Sistema de modelos configurado", 
                                     primary_model=settings.primary_ai_model,
                                     fallback_available=model_info['has_fallback'],
                                     reasoning_enabled=self.reasoning_enabled)
                
        except Exception as e:
            emoji_logger.system_error("Model Config", f"Erro cr√≠tico na configura√ß√£o de modelos: {e}")
            raise
    
    def _create_agentic_agent(self):
        """Cria o agente AGENTIC SDR com personalidade completa"""
        
        # Carregar prompt completo do AGENTIC SDR
        with open("app/prompts/prompt-agente.md", "r", encoding="utf-8") as f:
            agentic_prompt = f.read()
        
        # Adicionar instru√ß√µes de an√°lise contextual
        enhanced_prompt = agentic_prompt + """

## üß† AN√ÅLISE CONTEXTUAL INTELIGENTE

Voc√™ SEMPRE deve:
1. Buscar e analisar as √∫ltimas 100 mensagens da conversa
2. Entender o contexto completo antes de responder
3. Detectar padr√µes e necessidades n√£o expl√≠citas
4. Decidir inteligentemente quando acionar especialistas

### Sistema de Decis√£o Contextual
Analise TODOS os seguintes fatores antes de decidir:
- Hist√≥rico completo da conversa
- Est√°gio atual do lead no funil
- Complexidade da solicita√ß√£o
- Necessidade de expertise especializada
- Urg√™ncia e prioridade
- Estado emocional do lead

### Quando Acionar SDR Team
APENAS quando detectar necessidade REAL de:
- Qualifica√ß√£o t√©cnica avan√ßada
- Agendamento com m√∫ltiplas valida√ß√µes
- An√°lise de conta de luz com c√°lculos
- Follow-up estrat√©gico complexo
- Atualiza√ß√£o cr√≠tica no CRM
- Conhecimento t√©cnico muito espec√≠fico

LEMBRE-SE: Voc√™ resolve 90% das conversas sozinha!
"""
        
        self.agent = Agent(
            name="AGENTIC SDR",
            model=self.intelligent_model,  # CORRE√á√ÉO: Passar o wrapper, n√£o o modelo direto
            instructions=enhanced_prompt,
            tools=self.tools,
            storage=self.storage,  # CORRE√á√ÉO: Passar storage diretamente para o Agent
            memory=self.memory,    # Passar a mem√≥ria simples (ou None se falhou)
            knowledge=self.knowledge,
            show_tool_calls=False,
            markdown=True,
            debug_mode=settings.debug,
            # Context includes personality configurations
            context={
                "emotional_state": "ENTUSIASMADA",  # Estado padr√£o, ser√° sobrescrito em process_message
                "cognitive_load": 0.0,
                "current_time": datetime.now().strftime("%H:%M"),
                "day_of_week": datetime.now().strftime("%A"),
                "period_of_day": get_period_of_day(settings.timezone)  # Manh√£, Tarde ou Noite
            }
        )
        
        # Configurar as instructions no modelo wrapper para uso em temp_agents
        if hasattr(self.intelligent_model, 'set_agent_instructions'):
            self.intelligent_model.set_agent_instructions(enhanced_prompt)
    
    def _is_complex_message(self, message: str) -> bool:
        """
        Determina se a mensagem √© complexa e requer reasoning (OTIMIZADO)
        
        Crit√©rios mais restritivos para economizar tempo:
        - Mensagens muito curtas (< 15 chars) = simples
        - Sauda√ß√µes e respostas diretas = simples
        - Apenas perguntas ELABORADAS = complexa
        """
        message_lower = message.lower().strip()
        
        # Mensagens muito curtas s√£o sempre simples - AUMENTADO DE 10 PARA 15
        if len(message_lower) < 15:
            return False
            
        # Respostas diretas que N√ÉO precisam reasoning - EXPANDIDO
        simple_responses = {
            'oi', 'ol√°', 'bom dia', 'boa tarde', 'boa noite',
            'tudo bem', 'tudo certo', 'sim', 'n√£o', 'ok', 'certo', 
            'beleza', 'entendi', 'pode ser', 'claro', 'com certeza',
            'obrigado', 'obrigada', 'tchau', 'at√© mais', 'valeu',
            'ta bom', 'ta ok', 'legal', '√≥timo', 'perfeito',
            'isso', 'isso mesmo', 'exato', 'concordo'
        }
        
        # Se √© uma resposta simples, n√£o precisa reasoning
        if message_lower in simple_responses or any(
            message_lower.startswith(resp) and len(message_lower) < 25 
            for resp in simple_responses
        ):
            return False
        
        # S√ì ativar reasoning para quest√µes REALMENTE complexas
        complex_indicators = [
            'como funciona', 'me explica', 'n√£o entendi',
            'quanto custa', 'qual o valor', 'economia',
            'comparar', 'diferen√ßa', 'vantagem',
            'garantia', 'manuten√ß√£o', 'instala√ß√£o',
            'o que √©', 'por que', 'quando'
        ]
        
        # Precisa ter pelo menos 2 indicadores OU pergunta muito elaborada
        indicator_count = sum(1 for ind in complex_indicators if ind in message_lower)
        has_multiple_questions = message.count('?') > 1
        is_long_question = '?' in message and len(message) > 50
        
        return indicator_count >= 2 or has_multiple_questions or is_long_question
    
    async def analyze_conversation_context(
        self,
        phone: str,
        current_message: str
    ) -> Dict[str, Any]:
        """
        Analisa contexto completo da conversa
        
        Args:
            phone: N√∫mero do telefone
            current_message: Mensagem atual
            
        Returns:
            An√°lise contextual completa
        """
        try:
            # Buscar √∫ltimas 100 mensagens
            messages = await self.get_last_100_messages(phone)
            
            # An√°lise de padr√µes
            context_analysis = {
                "message_count": len(messages),
                "conversation_duration": self._calculate_duration(messages),
                "lead_engagement_level": self._analyze_engagement(messages),
                "detected_intents": self._detect_intents(messages),
                "emotional_trajectory": self._analyze_emotional_trajectory(messages),
                "key_topics": self._extract_key_topics(messages),
                "qualification_signals": self._detect_qualification_signals(messages),
                "objections_raised": self._extract_objections(messages),
                "decision_stage": self._determine_decision_stage(messages),
                "urgency_level": self._assess_urgency(messages, current_message)
            }
            
            # Determinar contexto principal
            context_analysis["primary_context"] = self._determine_primary_context(
                context_analysis
            )
            
            # Recomenda√ß√£o de a√ß√£o
            context_analysis["recommended_action"] = self._recommend_action(
                context_analysis
            )
            
            emoji_logger.agentic_context(f"Contexto identificado: {context_analysis['primary_context']}",
                                        messages_analyzed=len(messages),
                                        context_type=context_analysis['primary_context'])
            
            return context_analysis
            
        except Exception as e:
            emoji_logger.system_error("AGENTIC SDR", f"Erro na an√°lise contextual: {e}")
            return {
                "primary_context": ConversationContext.INITIAL_CONTACT.value,
                "error": str(e)
            }
    
    async def get_last_100_messages(self, identifier: str) -> List[Dict[str, Any]]:
        """
        Busca as √∫ltimas 100 mensagens do Supabase (sempre atualizado)
        
        Args:
            identifier: N√∫mero do telefone ou conversation_id
            
        Returns:
            Lista com √∫ltimas 100 mensagens
        """
        
        # LOG CR√çTICO: Rastrear todas as chamadas
        emoji_logger.system_info(f"üîç HIST√ìRICO: Buscando mensagens para identifier={identifier}")
        
        # Valida√ß√£o de entrada
        if not identifier:
            emoji_logger.system_error("HIST√ìRICO", "‚ùå Identifier vazio ou None!")
            return []
        
        try:
            # VALIDA√á√ÉO: Verificar se identifier √© v√°lido
            if not identifier:
                emoji_logger.system_warning("get_last_100_messages chamado com identifier None ou vazio")
                return []
                
            conversation_id = None
            
            # Determinar se √© phone ou conversation_id
            if identifier.startswith('conv_') or len(identifier) > 15:
                # Parece ser conversation_id
                conversation_id = identifier
                emoji_logger.system_info(f"Buscando mensagens por conversation_id: {conversation_id}")
            else:
                # Parece ser phone
                emoji_logger.system_info(f"Buscando mensagens por phone: {identifier}")
                conversation = await supabase_client.get_conversation_by_phone(identifier)
                if not conversation:
                    emoji_logger.system_warning(f"Conversa n√£o encontrada para phone: {identifier}")
                    return []
                conversation_id = conversation["id"]
                emoji_logger.system_info(f"Conversation_id encontrado: {conversation_id}")
            
            # Buscar √∫ltimas 100 mensagens
            emoji_logger.system_info(f"Executando query para conversation_id: {conversation_id}")
            
            # GARANTIR que sempre tentamos buscar 100 mensagens
            query = supabase_client.client.table("messages")\
                .select("*")\
                .eq("conversation_id", conversation_id)\
                .order("created_at", desc=True)\
                .limit(100)
            
            response = query.execute()  # Removido await - cliente s√≠ncrono
            messages = response.data if response.data else []
            
            # Log detalhado para debug
            emoji_logger.system_info(f"üìä QUERY EXECUTADA:")
            emoji_logger.system_info(f"  ‚Ä¢ Conversation ID: {conversation_id}")
            emoji_logger.system_info(f"  ‚Ä¢ Mensagens encontradas: {len(messages)}")
            emoji_logger.system_info(f"  ‚Ä¢ Limite solicitado: 100")
            
            # Log das primeiras e √∫ltimas mensagens para debug
            if messages:
                first_msg = messages[0]
                last_msg = messages[-1]
                emoji_logger.system_info(f"  ‚Ä¢ Primeira msg: {first_msg.get('created_at', 'N/A')} - {first_msg.get('sender', 'N/A')}")
                emoji_logger.system_info(f"  ‚Ä¢ √öltima msg: {last_msg.get('created_at', 'N/A')} - {last_msg.get('sender', 'N/A')}")
            
            # Se encontrou menos de 100 mensagens, informar
            if len(messages) < 100:
                emoji_logger.system_warning(f"Apenas {len(messages)} mensagens dispon√≠veis (menos que o limite de 100)")
            
            # Reverter para ordem cronol√≥gica
            messages.reverse()
            
            # Log de sucesso com informa√ß√£o completa
            success_msg = f"Mensagens recuperadas: {len(messages)}"
            if len(messages) < 100:
                success_msg += f" (conversa tem apenas {len(messages)} mensagens no total)"
            else:
                success_msg += " (limite de 100 atingido)"
                
            emoji_logger.supabase_success(success_msg, execution_time=0.1)
            
            # Retornar mensagens diretamente (sem cache)
            return messages
            
        except Exception as e:
            emoji_logger.supabase_error(f"Erro ao buscar mensagens: {e}",
                                       table="conversations")
            return []
    
    async def detect_emotional_triggers(
        self,
        messages: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        Detecta gatilhos emocionais na conversa
        
        Args:
            messages: Hist√≥rico de mensagens
            
        Returns:
            Gatilhos emocionais detectados
        """
        # Verificar se an√°lise emocional est√° habilitada
        if not self.emotional_triggers_enabled:
            return {
                "enabled": False,
                "message": "An√°lise emocional desabilitada"
            }
        
        triggers = {
            "frustration_indicators": 0,
            "excitement_indicators": 0,
            "hesitation_indicators": 0,
            "urgency_indicators": 0,
            "trust_indicators": 0
        }
        
        # Palavras-chave para cada emo√ß√£o
        frustration_words = ["demora", "dif√≠cil", "complicado", "n√£o entendo", "problema"]
        excitement_words = ["√≥timo", "excelente", "adorei", "perfeito", "maravilha"]
        hesitation_words = ["n√£o sei", "talvez", "preciso pensar", "d√∫vida", "ser√°"]
        urgency_words = ["urgente", "r√°pido", "agora", "hoje", "imediato"]
        trust_words = ["confio", "acredito", "verdade", "s√©rio", "garantia"]
        
        for msg in messages[-20:]:  # √öltimas 20 mensagens
            content = msg.get("content", "").lower()
            
            for word in frustration_words:
                if word in content:
                    triggers["frustration_indicators"] += 1
            
            for word in excitement_words:
                if word in content:
                    triggers["excitement_indicators"] += 1
            
            for word in hesitation_words:
                if word in content:
                    triggers["hesitation_indicators"] += 1
            
            for word in urgency_words:
                if word in content:
                    triggers["urgency_indicators"] += 1
            
            for word in trust_words:
                if word in content:
                    triggers["trust_indicators"] += 1
        
        # Determinar estado emocional dominante
        max_trigger = max(triggers, key=triggers.get)
        triggers["dominant_emotion"] = max_trigger.replace("_indicators", "")
        
        return triggers
    
    async def should_call_sdr_team(
        self,
        context_analysis: Dict[str, Any],
        current_message: str
    ) -> Tuple[bool, Optional[str], str]:
        """
        Decide inteligentemente se deve chamar SDR Team
        
        Args:
            context_analysis: An√°lise contextual completa
            current_message: Mensagem atual
            
        Returns:
            (deve_chamar, agente_especifico, raz√£o)
        """
        # An√°lise multi-fatorial para decis√£o
        decision_factors = {
            "complexity_score": 0,
            "specialization_needed": False,
            "confidence_level": 1.0,
            "recommended_agent": None,
            "reasoning": []
        }
        
        # Fator 1: Complexidade da solicita√ß√£o - CALEND√ÅRIO
        # ‚úÖ CORRIGIDO: Keywords espec√≠ficas para evitar falsos positivos
        calendar_keywords = [
            "agendar reuni√£o", "marcar reuni√£o", "marcar encontro", "marcar meeting",
            "hor√°rio para reuni√£o", "disponibilidade para", "agenda dispon√≠vel",
            "calend√°rio livre", "encontro para", "meeting para", "apresenta√ß√£o comercial",
            "reagendar", "remarcar reuni√£o", "cancelar reuni√£o",
            "que dia pode ser", "qual hor√°rio", "quando podemos nos reunir",
            "semana que vem para reuni√£o", "pr√≥xima semana reuni√£o", 
            "amanh√£ para reuni√£o", "hoje para reuni√£o", "vamos marcar"
        ]
        
        # ‚úÖ NOVO: Filtro de sauda√ß√£o para evitar falsos positivos
        greeting_indicators = ["ol√°", "oi", "bom dia", "boa tarde", "boa noite", "tudo bem", "tchau", "obrigado"]
        is_simple_greeting = any(greeting in current_message.lower() for greeting in greeting_indicators) and len(current_message.split()) <= 5
        
        # ‚úÖ CORRIGIDO: Indicadores negativos para agendamento
        negative_indicators = ["n√£o", "nao", "sem interesse", "n√£o quero", "j√° tenho", "n√£o pedi"]
        has_negative_context = any(neg in current_message.lower() for neg in negative_indicators)
        
        # VERIFICAR SE √â FOLLOW-UP/REENGAJAMENTO antes de detectar calend√°rio
        followup_indicators = ["reengajamento", "follow-up", "n√£o √© agendamento", "parou de responder"]
        is_followup_message = any(indicator in current_message.lower() for indicator in followup_indicators)
        
        # ‚úÖ CORRIGIDO: L√≥gica mais inteligente para detectar agendamento REAL
        calendar_detected = any(word in current_message.lower() for word in calendar_keywords)
        is_real_calendar_request = calendar_detected and not is_simple_greeting and not has_negative_context and not is_followup_message
        
        if is_real_calendar_request:
            # ‚úÖ CORRIGIDO: Score mais conservador para evitar ativa√ß√£o desnecess√°ria
            decision_factors["complexity_score"] += 0.6  # Reduzido de 0.8 para 0.6
            decision_factors["recommended_agent"] = "CalendarAgent"
            decision_factors["reasoning"].append("üóìÔ∏è Solicita√ß√£o de agendamento detectada - Ativando CalendarAgent")
            
            # Log detalhado para debug
            logger.info(f"üìÖ CALEND√ÅRIO DETECTADO - Score: {decision_factors['complexity_score']}")
            logger.info(f"üìÖ Mensagem: {current_message[:100]}...")
            logger.info(f"üìÖ Agent recomendado: CalendarAgent")
        elif is_followup_message:
            # √â uma mensagem de follow-up, n√£o de agendamento
            decision_factors["reasoning"].append("üîÑ Mensagem de follow-up detectada - evitando CalendarAgent")
            logger.info(f"üîÑ FOLLOW-UP DETECTADO - Evitando CalendarAgent")
            logger.info(f"üîÑ Mensagem: {current_message[:100]}...")
        
        # Fator 2: An√°lise de conta necess√°ria
        if context_analysis.get("has_bill_image") or \
           "conta de luz" in current_message.lower():
            decision_factors["complexity_score"] += 0.5
            decision_factors["recommended_agent"] = "BillAnalyzerAgent"
            decision_factors["reasoning"].append("An√°lise de conta necess√°ria")
        
        # Fator 3: Lead de alto valor
        qualification_signals = context_analysis.get("qualification_signals", {})
        if qualification_signals.get("bill_value", 0) > 4000:
            decision_factors["complexity_score"] += 0.3
            if not decision_factors["recommended_agent"]:
                decision_factors["recommended_agent"] = "QualificationAgent"
            decision_factors["reasoning"].append("Lead de alto valor detectado")
        
        # Fator 4: M√∫ltiplas obje√ß√µes
        if len(context_analysis.get("objections_raised", [])) > 2:
            decision_factors["complexity_score"] += 0.4
            decision_factors["reasoning"].append("M√∫ltiplas obje√ß√µes necessitam tratamento especializado")
        
        # Fator 5: Est√°gio avan√ßado no funil
        if context_analysis.get("decision_stage") in ["negotiation", "closing"]:
            decision_factors["complexity_score"] += 0.3
            decision_factors["reasoning"].append("Est√°gio avan√ßado requer expertise")
        
        # Fator 6: Necessidade de follow-up estrat√©gico
        if context_analysis.get("conversation_duration", 0) > 24:  # horas
            decision_factors["complexity_score"] += 0.2
            if not decision_factors["recommended_agent"]:
                decision_factors["recommended_agent"] = "FollowUpAgent"
            decision_factors["reasoning"].append("Follow-up estrat√©gico necess√°rio")
        
        # Decis√£o final baseada em threshold inteligente
        should_call = decision_factors["complexity_score"] >= 0.7
        
        if should_call:
            reason = f"Score de complexidade: {decision_factors['complexity_score']:.2f}. " + \
                    ". ".join(decision_factors["reasoning"])
            
            emoji_logger.agentic_decision(f"Chamar SDR Team - {decision_factors['recommended_agent']}",
                                         score=decision_factors['complexity_score'],
                                         recommended_agent=decision_factors['recommended_agent'])
            return True, decision_factors["recommended_agent"], reason
        
        emoji_logger.agentic_decision("AGENTIC SDR resolve sozinha",
                                     score=decision_factors['complexity_score'])
        return False, None, "AGENTIC SDR pode resolver esta conversa"
    
    def _get_media_type_from_mimetype(self, mimetype: str) -> str:
        """
        Mapeia mimetype para tipo de m√≠dia
        SIMPLES E FUNCIONAL!
        """
        if not mimetype:
            return "unknown"
        
        mimetype_lower = mimetype.lower()
        
        # Mapeamento simples e direto
        if "image" in mimetype_lower:
            return "image"
        elif "audio" in mimetype_lower:
            return "audio"
        elif "video" in mimetype_lower:
            return "video"
        elif "pdf" in mimetype_lower:
            return "pdf"
        elif mimetype_lower in ["application/vnd.openxmlformats-officedocument.wordprocessingml.document", "application/msword"]:
            return "document"
        elif "sticker" in mimetype_lower or "webp" in mimetype_lower:
            return "sticker"
        else:
            return "document"  # Default para documentos
    
    async def process_multimodal_content(
        self,
        media_type: str,
        media_data: str,
        caption: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Processa conte√∫do multimodal (imagens, √°udio, documentos)
        
        Args:
            media_type: Tipo de m√≠dia (image, audio, document, pdf)
            media_data: Dados da m√≠dia em base64
            caption: Legenda opcional
            
        Returns:
            An√°lise do conte√∫do multimodal com estrutura padronizada
        """
        # Fun√ß√£o helper para detectar formato
        def detect_and_clean_base64(data: str) -> tuple[str, str]:
            """
            Detecta e limpa dados base64
            Retorna: (base64_limpo, formato_detectado)
            """
            if not data:
                return "", "empty"
            
            # Se come√ßa com data URL, extrair apenas o base64
            if data.startswith("data:"):
                if ";base64," in data:
                    clean_data = data.split(";base64,")[1]
                    return clean_data, "data_url"
                return "", "invalid_data_url"
            
            # Se √© URL HTTP, n√£o √© base64
            if data.startswith(("http://", "https://")):
                return "", "url"
            
            # Verificar se √© base64 v√°lido
            if len(data) > 50:
                try:
                    # Tenta decodificar uma amostra
                    import base64
                    test = base64.b64decode(data[:100], validate=True)
                    return data, "base64"
                except:
                    # Pode ser texto ou outro formato
                    return "", "invalid"
            
            return "", "too_short"
        import time
        import asyncio
        start_time = time.time()
        
        # Configurar timeout de 30 segundos para todo o processamento
        MULTIMODAL_TIMEOUT = 30
        
        async def process_with_timeout():
            """Processa m√≠dia com timeout"""
            # Usar nonlocal para acessar vari√°veis do escopo externo
            nonlocal media_data
            
            emoji_logger.system_info(f"üéØ MULTIMODAL: Iniciando processamento")
            emoji_logger.system_info(f"üìå Tipo: {media_type.upper()}")
            emoji_logger.system_info(f"üìä Tamanho dados base64: {len(media_data):,} caracteres")
            emoji_logger.system_info(f"üí¨ Caption: {caption[:50] + '...' if caption and len(caption) > 50 else caption or 'Sem legenda'}")
            emoji_logger.system_info(f"‚è∞ Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            emoji_logger.system_info("‚ïê" * 50)
            
            # Verificar se an√°lise multimodal est√° habilitada
            if not self.multimodal_enabled:
                emoji_logger.system_warning("An√°lise multimodal desabilitada nas configura√ß√µes")
                return {
                    "type": media_type,
                    "enabled": False,
                    "message": "An√°lise multimodal desabilitada"
                }
            
            # Validar entrada
            if not media_data:
                emoji_logger.system_warning(f"‚ùå MULTIMODAL: Dados vazios para {media_type}")
                emoji_logger.system_warning(f"‚è±Ô∏è Tempo decorrido: {time.time() - start_time:.2f}s")
                return {
                    "type": media_type,
                    "error": "Dados de m√≠dia n√£o fornecidos"
                }
            
            # Validar tipo de m√≠dia
            valid_types = ["image", "audio", "document", "pdf", "video"]
            if media_type not in valid_types:
                emoji_logger.system_warning(f"‚ùå MULTIMODAL: Tipo inv√°lido '{media_type}'")
                emoji_logger.system_warning(f"üìù Tipos v√°lidos: {', '.join(valid_types)}")
                return {
                    "type": media_type,
                    "error": f"Tipo de m√≠dia '{media_type}' n√£o suportado"
                }
            if media_type == "image":
                # AGNO Framework - Processamento nativo de imagens
                emoji_logger.system_info("üåÜ " + "=" * 45)
                emoji_logger.system_info("üåÜ PROCESSAMENTO DE IMAGEM INICIADO")
                emoji_logger.system_info("üåÜ " + "=" * 45)
                
                # Validar e limpar base64
                clean_base64, format_type = detect_and_clean_base64(media_data)
                
                emoji_logger.system_info(f"üîç IMAGEM - Formato detectado: {format_type}")
                
                if format_type in ["empty", "invalid", "too_short", "url"]:
                    emoji_logger.system_warning(f"‚ùå IMAGEM: Formato inv√°lido - {format_type}")
                    if format_type == "url":
                        emoji_logger.system_warning("üí° Dica: URL detectada, precisa baixar primeiro")
                    return {
                        "type": "image",
                        "error": f"Dados de imagem inv√°lidos (formato: {format_type})",
                        "status": "invalid_format",
                        "format_detected": format_type
                    }
                
                # Usar o base64 limpo
                media_data = clean_base64
                
                if not media_data:
                    emoji_logger.system_warning("‚ùå IMAGEM: Dados vazios ap√≥s limpeza")
                    return {
                        "type": "image",
                        "error": "Dados de imagem vazios",
                        "status": "no_data"
                    }
                
                # Verificar tamanho da imagem
                data_size = len(media_data)
                estimated_bytes = (data_size * 3) // 4  # Estimativa de bytes decodificados
                estimated_kb = estimated_bytes / 1024
                estimated_mb = estimated_kb / 1024
                
                emoji_logger.system_info(f"üìà IMAGEM - M√©tricas:")
                emoji_logger.system_info(f"  ‚Ä¢ Base64: {data_size:,} caracteres")
                emoji_logger.system_info(f"  ‚Ä¢ Estimado: {estimated_bytes:,} bytes ({estimated_kb:.1f} KB / {estimated_mb:.2f} MB)")
                
                # Validar qualidade da imagem ANTES de enviar
                try:
                    import base64 as b64_module
                    from PIL import Image
                    from io import BytesIO
                    
                    # Decodificar imagem
                    img_bytes = b64_module.b64decode(media_data)
                    img = Image.open(BytesIO(img_bytes))
                    width, height = img.size
                    
                    emoji_logger.system_info(f"üìê IMAGEM - Dimens√µes: {width}x{height} pixels")
                    
                    # Validar tamanho m√≠nimo (100x100)
                    if width < 100 or height < 100:
                        emoji_logger.system_error("Image Validation", f"‚ùå IMAGEM: Muito pequena ({width}x{height}). M√≠nimo: 100x100")
                        return {
                            "type": "image",
                            "error": f"Imagem muito pequena ({width}x{height} pixels). Envie uma imagem maior que 100x100.",
                            "status": "too_small",
                            "dimensions": {"width": width, "height": height}
                        }
                    
                    # Validar tamanho m√°ximo (10MB)
                    if len(img_bytes) > 10 * 1024 * 1024:
                        emoji_logger.system_error("Image Validation", f"‚ùå IMAGEM: Muito grande ({len(img_bytes) / 1024 / 1024:.1f}MB). M√°ximo: 10MB")
                        return {
                            "type": "image",
                            "error": "Imagem muito grande. Por favor, envie uma imagem menor que 10MB.",
                            "status": "too_large",
                            "size_mb": len(img_bytes) / 1024 / 1024
                        }
                    
                    # Avisos sobre qualidade
                    if data_size < 50000:  # Menos de 50KB em base64
                        emoji_logger.system_warning("‚ö†Ô∏è IMAGEM: Poss√≠vel thumbnail detectada (<50KB)")
                    elif estimated_mb > 2:
                        emoji_logger.system_warning(f"‚ö†Ô∏è IMAGEM: Tamanho grande ({estimated_mb:.2f} MB) - pode causar lentid√£o")
                    
                except Exception as val_error:
                    emoji_logger.system_error("Image Validation", f"‚ùå Erro ao validar imagem: {str(val_error)}")
                    # Continuar mesmo com erro de valida√ß√£o
                
                # Preparar prompt espec√≠fico para an√°lise (simplificado para evitar erros)
                analysis_prompt = f"""Analise esta imagem e extraia as informa√ß√µes vis√≠veis.
{f'Contexto: {caption}' if caption else ''}

Retorne em formato estruturado:
- Tipo de documento
- Valores encontrados
- Datas
- Nomes ou empresas
- Outras informa√ß√µes relevantes"""
                
                try:
                    # AGNO Framework Solution: Usar agno.media.Image nativo
                    import base64
                    import google.generativeai as genai
                    
                    emoji_logger.system_info("üîç Etapa 1/4: Decodificando base64...")
                    
                    # AGNO Framework Solution: Usar agno.media.Image nativo
                    # Validar dados
                    if not media_data:
                        raise ValueError("Dados da imagem vazios")
                    
                    # Decodificar base64 para bytes
                    decode_start = time.time()
                    image_bytes = base64.b64decode(media_data)
                    original_size = len(image_bytes)
                    decode_time = time.time() - decode_start
                    
                    emoji_logger.system_info(f"‚úÖ Decodifica√ß√£o completa em {decode_time:.2f}s")
                    emoji_logger.system_info(f"  ‚Ä¢ Tamanho real: {original_size:,} bytes")
                    emoji_logger.system_info(f"  ‚Ä¢ Taxa compress√£o: {(1 - original_size/data_size)*100:.1f}%")
                    
                    # AGNO Framework - Detec√ß√£o robusta de formato de imagem
                    emoji_logger.system_info("üîç Etapa 2/4: Detectando formato da imagem...")
                    detect_start = time.time()
                    detection_result = self.agno_media_detector.detect_media_type(image_bytes)
                    detect_time = time.time() - detect_start
                    
                    if not detection_result['detected']:
                        emoji_logger.system_warning(f"‚ùå IMAGEM: Formato n√£o reconhecido")
                        emoji_logger.system_warning(f"  ‚Ä¢ Magic bytes: {detection_result.get('magic_bytes', 'N/A')}")
                        emoji_logger.system_warning(f"  ‚Ä¢ Tempo detec√ß√£o: {detect_time:.2f}s")
                        # Usar fallback suggestion
                        fallback_msg = detection_result.get('fallback_suggestion', 'Formato n√£o suportado')
                        return {
                            "type": "image",
                            "error": f"Formato n√£o suportado: {fallback_msg}",
                            "status": "unsupported_format",
                            "agno_detection": detection_result
                        }
                    else:
                        emoji_logger.system_info(f"‚úÖ Formato detectado: {detection_result['format'].upper()}")
                        emoji_logger.system_info(f"  ‚Ä¢ Confian√ßa: {detection_result.get('confidence', 'N/A')}")
                        emoji_logger.system_info(f"  ‚Ä¢ Tempo detec√ß√£o: {detect_time:.2f}s")
                    
                    format_hint = detection_result.get('format', 'unknown')
                    
                    # Verificar se recommended_params existe antes de acessar
                    if 'recommended_params' in detection_result:
                        agno_params = detection_result['recommended_params']
                    else:
                        # Usar par√¢metros padr√£o se n√£o houver recomenda√ß√£o
                        logger.warning(f"‚ö†Ô∏è Sem recommended_params para formato: {format_hint}")
                        agno_params = {
                            'format': 'auto',
                            'detail': 'high'
                        }
                    
                    emoji_logger.agentic_thinking(f"AGNO detectou: {format_hint} (confian√ßa: {detection_result.get('confidence', 'unknown')})")
                    
                    # üîß CORRE√á√ÉO MULTIMODAL: Usar PIL + Gemini diretamente (sem AGNO)
                    # Esta corre√ß√£o resolve o erro 400 INVALID_ARGUMENT e a lat√™ncia de 42s
                    emoji_logger.system_info("üîß Usando PIL + Gemini direto (corre√ß√£o implementada)")
                    
                    try:
                        # Processamento direto com PIL + Gemini (sem AGNO Framework)
                        from io import BytesIO
                        from PIL import Image as PILImage
                        import google.generativeai as genai
                        
                        # Decodificar base64 para usar com PIL
                        img_bytes = base64.b64decode(media_data)
                        img = PILImage.open(BytesIO(img_bytes))
                        
                        # Configurar Gemini com modelo Vision correto
                        from app.config import settings
                        genai.configure(api_key=settings.google_api_key)
                        vision_model = genai.GenerativeModel('gemini-1.5-flash')  # Modelo com capacidade vision
                        
                        # Prompt espec√≠fico para an√°lise de contas de energia
                        if "conta" in analysis_prompt.lower() or "energia" in analysis_prompt.lower():
                            enhanced_prompt = """Analise esta conta de energia el√©trica e extraia as seguintes informa√ß√µes:
                            1. Valor total a pagar (em R$)
                            2. Consumo mensal em kWh
                            3. Nome completo do titular da conta
                            4. Endere√ßo completo da instala√ß√£o
                            5. M√™s de refer√™ncia da conta
                            6. Vencimento da fatura
                            
                            Responda em formato estruturado e claro. Se n√£o conseguir identificar alguma informa√ß√£o, indique como "N√£o identificado"."""
                        else:
                            enhanced_prompt = analysis_prompt
                        
                        emoji_logger.system_info("üì§ Enviando imagem para Gemini Vision com prompt otimizado...")
                        
                        # Enviar imagem com prompt otimizado ao Gemini
                        response = vision_model.generate_content([enhanced_prompt, img])
                        analysis_content = response.text if hasattr(response, 'text') else str(response)
                        
                        emoji_logger.system_info("‚úÖ PIL + Gemini direto: Sucesso (lat√™ncia otimizada)")
                            
                    except Exception as pil_gemini_error:
                        emoji_logger.system_error("PIL + Gemini direto falhou", f"Erro: {str(pil_gemini_error)}")
                        return {
                            "type": "image",
                            "error": f"N√£o foi poss√≠vel processar a imagem: {str(pil_gemini_error)}",
                            "status": "error",
                            "suggestion": "Tente enviar a imagem em formato JPEG ou PNG"
                        }
                        
                    emoji_logger.agentic_multimodal("An√°lise de imagem conclu√≠da com sucesso")
                    
                    # Verificar se √© conta de luz atrav√©s da interpreta√ß√£o do Gemini
                    bill_keywords = ["conta", "energia", "kwh", "tarifa", "consumo", "fatura"]
                    is_bill = any(word in analysis_content.lower() for word in bill_keywords)
                    
                    if is_bill:
                        emoji_logger.agentic_multimodal("Conta de luz detectada", media_type="bill_image")
                        # Extrair valor da conta se poss√≠vel
                        import re
                        
                        # Buscar padr√£o de valor monet√°rio na an√°lise
                        valor_match = re.search(r'R\$\s*(\d+[.,]\d{2})', analysis_content)
                        bill_amount = None
                        if valor_match:
                            # Converter v√≠rgula para ponto e para float
                            bill_amount = float(valor_match.group(1).replace(',', '.'))
                            emoji_logger.system_info(f"üí∞ Valor da conta detectado: R$ {bill_amount:.2f}")
                        
                        return {
                            "type": "bill_image",
                            "needs_analysis": True,
                            "content": analysis_content,
                            "bill_amount": bill_amount,  # Adicionar valor extra√≠do
                            "is_bill": True  # Garantir que √© reconhecido como conta
                        }
                    else:
                        # Imagem gen√©rica
                        return {
                            "type": "image",
                            "content": analysis_content,
                            "caption": caption,
                            "processed": True
                        }
                    
                except Exception as img_error:
                    emoji_logger.system_error("Vision API", f"Erro ao analisar imagem: {str(img_error)[:100]}")
                    
                    # Tentar extrair informa√ß√µes do erro para diagn√≥stico
                    error_details = str(img_error)
                    if "quota" in error_details.lower():
                        error_msg = "Limite de API excedido"
                    elif "invalid" in error_details.lower():
                        error_msg = "Formato de imagem inv√°lido"
                    elif "timeout" in error_details.lower():
                        error_msg = "Timeout na an√°lise"
                    else:
                        error_msg = f"Erro na an√°lise: {str(img_error)[:100]}"
                    
                    return {
                        "type": "image",
                        "error": error_msg,
                        "status": "error",
                        "is_thumbnail": data_size < 50000
                    }
            
            elif media_type == "audio":
                # Processar √°udio (transcri√ß√£o)
                emoji_logger.system_info("Processamento de √°udio solicitado")
                
                # Verificar se transcri√ß√£o est√° habilitada
                if not self.settings.enable_voice_message_transcription:
                    return {
                        "type": "audio",
                        "status": "disabled",
                        "message": "Transcri√ß√£o de √°udio desabilitada"
                    }
                
                # Usar o novo AudioTranscriber
                try:
                    from app.services.audio_transcriber import audio_transcriber
                    
                    emoji_logger.agentic_thinking("Transcrevendo √°udio com AudioTranscriber...")
                    
                    # Detectar mimetype do √°udio (geralmente audio/ogg no WhatsApp)
                    mimetype = "audio/ogg"  # Padr√£o do WhatsApp
                    
                    # Transcrever
                    result = await audio_transcriber.transcribe_from_base64(
                        media_data,
                        mimetype=mimetype,
                        language="pt-BR"
                    )
                    
                    if result["status"] == "success":
                        # SIMPLES: Apenas retornar a transcri√ß√£o
                        # N√£o precisa processar com agente adicional
                        transcribed_text = result["text"]
                        
                        emoji_logger.agentic_multimodal(
                            f"Audio transcrito com sucesso: {len(transcribed_text)} caracteres",
                            media_type="audio",
                            duration=result.get("duration", 0)
                        )
                        
                        return {
                            "type": "audio",
                            "transcription": transcribed_text,
                            "duration": result.get("duration", 0),
                            "engine": result.get("engine", "Google Speech Recognition"),
                            "status": "transcribed"
                        }
                    elif result["status"] == "unclear":
                        return {
                            "type": "audio",
                            "status": "unclear",
                            "message": "N√£o foi poss√≠vel compreender o √°udio claramente",
                            "transcription": result.get("text", "")
                        }
                    else:
                        emoji_logger.system_warning(f"‚ùå √ÅUDIO: Erro na transcri√ß√£o")
                        emoji_logger.system_warning(f"  ‚Ä¢ Erro: {result.get('error', 'Erro desconhecido')}")
                        emoji_logger.system_warning(f"  ‚Ä¢ Tempo total: {time.time() - start_time:.2f}s")
                        return {
                            "type": "audio",
                            "status": "error",
                            "message": f"Erro na transcri√ß√£o: {result.get('error', 'Erro desconhecido')}"
                        }
                        
                except Exception as e:
                    emoji_logger.system_warning(f"Erro ao transcrever √°udio: {e}")
                    return {
                        "type": "audio",
                        "status": "error",
                        "message": f"Erro ao processar √°udio: {str(e)}"
                    }
            
            elif media_type in ["document", "pdf"]:
                # AGNO Framework - Processamento nativo de documentos
                emoji_logger.agentic_multimodal("Processando documento com AGNO Framework nativo")
                
                try:
                    # AGNO Framework Solution: Usar document readers nativos
                    import base64
                    from io import BytesIO
                    
                    # Decodificar base64 para bytes
                    document_bytes = base64.b64decode(media_data)
                    original_size = len(document_bytes)
                    emoji_logger.agentic_multimodal(f"Documento decodificado: {original_size:,} bytes")
                    
                    # AGNO Framework - Detec√ß√£o robusta de formato de documento
                    detection_result = self.agno_media_detector.detect_media_type(document_bytes)
                    
                    if not detection_result['detected']:
                        emoji_logger.system_warning(f"Formato de documento n√£o reconhecido pelo AGNO: {detection_result.get('magic_bytes', 'N/A')}")
                        # Usar fallback suggestion
                        fallback_msg = detection_result.get('fallback_suggestion', 'Formato n√£o suportado')
                        return {
                            "type": "document",
                            "error": f"Formato n√£o suportado: {fallback_msg}",
                            "status": "unsupported_format",
                            "agno_detection": detection_result
                        }
                    
                    document_type = detection_result.get('format', 'unknown')
                    
                    # Verificar se recommended_params existe antes de acessar
                    if 'recommended_params' in detection_result:
                        agno_params = detection_result['recommended_params']
                    else:
                        # Usar par√¢metros padr√£o se n√£o houver recomenda√ß√£o
                        logger.warning(f"‚ö†Ô∏è Sem recommended_params para documento: {document_type}")
                        agno_params = {
                            'reader_class': 'PDFReader',
                            'ocr_enabled': True,
                            'max_pages': None
                        }
                    
                    is_pdf = document_type == 'pdf'
                    is_docx = document_type == 'docx'
                    
                    emoji_logger.agentic_thinking(f"AGNO detectou documento: {document_type} (confian√ßa: {detection_result.get('confidence', 'unknown')})")
                    
                    # Determinar tipo e usar AGNO reader apropriado
                    extracted_text = ""
                    doc_metadata = {}
                    
                    if is_pdf or is_docx:
                        try:
                            # Usar processador centralizado de documentos
                            emoji_logger.agentic_thinking(f"Processando documento {document_type} com EnhancedDocumentProcessor...")
                            
                            # Processar documento usando fun√ß√£o SIMPLES (substitui document_processor_enhanced.py)
                            result = await self._process_document_simple(
                                data=document_bytes,
                                filename=f"document.{document_type}"
                            )
                            
                            if result.get('status') == 'success':
                                extracted_text = result.get('content', '')
                                doc_metadata = {
                                    "reader": "enhanced_document_processor",
                                    "format": document_type,
                                    "size_bytes": original_size,
                                    "text_extracted": result.get('text_extracted', False),
                                    "images_processed": result.get('images_processed', 0),
                                    "ocr_content": result.get('ocr_content', False)
                                }
                                
                                if is_pdf:
                                    doc_metadata["pages"] = result.get('pages', 0)
                                elif is_docx:
                                    doc_metadata["sections"] = result.get('sections', 0)
                                
                                emoji_logger.agentic_thinking(f"Documento processado com sucesso: {len(extracted_text)} caracteres extra√≠dos")
                            else:
                                raise Exception(f"Falha no processamento: {result.get('error', 'Unknown error')}")
                            
                        except Exception as doc_error:
                            emoji_logger.system_error("Document Processing", f"Erro ao processar documento: {str(doc_error)}")
                            # N√£o lan√ßar exce√ß√£o, retornar erro estruturado
                            return {
                                "type": "document",
                                "error": str(doc_error),
                                "status": "error",
                                "message": f"Erro ao processar documento: {str(doc_error)[:100]}"
                            }
                    
                    else:
                        # Formato n√£o suportado pelos readers AGNO
                        raise Exception(f"Formato de documento n√£o suportado. Magic bytes: {magic_bytes[:8].hex()}")
                    
                    # Processar resultado
                    result = {
                        "status": "success",
                        "text": extracted_text,
                        "document_type": document_type,
                        "metadata": doc_metadata
                    }
                    
                    if result["status"] == "success":
                        extracted_text = result["text"]
                        doc_type = result.get("document_type", "documento")
                        
                        # Criar contexto para an√°lise do documento
                        doc_context = f"""O cliente enviou um {doc_type} com o seguinte conte√∫do:
                        
                        {extracted_text[:3000]}...
                        
                        Documento completo: {result.get('pages', 'N/A')} p√°gina(s)
                        Tipo identificado: {doc_type}
                        
                        Por favor, analise o documento e:
                        1. Identifique as informa√ß√µes principais
                        2. Se for uma conta de luz, extraia valor e consumo
                        3. Se for outro documento, resuma os pontos importantes"""
                        
                        # Usar IntelligentModelFallback diretamente para evitar depend√™ncia do OpenAI
                        emoji_logger.agentic_thinking("Analisando documento com IntelligentModelFallback...")
                        try:
                            # Criar um agente tempor√°rio apenas com o modelo inteligente
                            from agno.agent import Agent as AgnoAgent
                            
                            temp_agent = AgnoAgent(
                                model=self.intelligent_model,  # Usa o wrapper com fallback
                                markdown=True,
                                show_tool_calls=False,
                                instructions="Voc√™ √© um assistente especializado em an√°lise de documentos. Extraia todas as informa√ß√µes relevantes de forma detalhada."
                            )
                            
                            # Processar documento
                            response = temp_agent.run(doc_context)
                            
                            # Extrair conte√∫do da resposta
                            if hasattr(response, 'content'):
                                agent_response = response.content
                            elif isinstance(response, dict) and 'content' in response:
                                agent_response = response['content']
                            elif isinstance(response, str):
                                agent_response = response
                            else:
                                agent_response = str(response)
                            
                            emoji_logger.agentic_thinking(f"Documento analisado com sucesso: {len(str(agent_response))} caracteres")
                        except Exception as analysis_error:
                            emoji_logger.system_error("Document Analysis", f"Erro ao analisar: {str(analysis_error)}")
                            agent_response = "N√£o foi poss√≠vel analisar o documento neste momento."
                        
                        emoji_logger.agentic_multimodal(
                            f"Documento processado: {doc_type}, {len(extracted_text)} caracteres",
                            media_type="document",
                            pages=result.get("pages", 0)
                        )
                        
                        return {
                            "type": "document",
                            "document_type": doc_type,
                            "content": extracted_text[:5000],  # Limitar resposta
                            "analysis": agent_response,
                            "pages": result.get("pages", 0),
                            "method": result.get("method", "unknown"),
                            "status": "processed"
                        }
                    elif result["status"] == "no_text":
                        # PDF escaneado (precisa OCR)
                        return {
                            "type": "document",
                            "status": "scanned",
                            "message": "Documento parece ser escaneado. Tente enviar como imagem para an√°lise visual.",
                            "pages": result.get("pages", 0)
                        }
                    else:
                        return {
                            "type": "document",
                            "status": "error",
                            "message": f"Erro ao processar documento: {result.get('error', 'Erro desconhecido')}"
                        }
                        
                except Exception as e:
                    emoji_logger.system_warning(f"Erro ao processar documento: {e}")
                    return {
                        "type": "document",
                        "status": "error",
                        "message": f"Erro ao processar documento: {str(e)}"
                    }
            
            elif media_type == "video":
                # Processar v√≠deo
                emoji_logger.system_info("Processamento de v√≠deo solicitado")
                return {
                    "type": "video",
                    "status": "not_supported",
                    "message": "Processamento de v√≠deo n√£o implementado"
                }
            
            # Tipo desconhecido (n√£o deveria chegar aqui devido √† valida√ß√£o)
            return {
                "type": media_type,
                "processed": False,
                "message": f"Tipo {media_type} n√£o tem processamento espec√≠fico"
            }
            
        # Executar com timeout
        try:
            result = await asyncio.wait_for(
                process_with_timeout(),
                timeout=MULTIMODAL_TIMEOUT
            )
            
            # M√©tricas finais de sucesso
            total_time = time.time() - start_time
            emoji_logger.system_info("‚ïê" * 50)
            emoji_logger.system_info(f"‚úÖ MULTIMODAL: Processamento conclu√≠do")
            emoji_logger.system_info(f"  ‚Ä¢ Tipo: {media_type}")
            emoji_logger.system_info(f"  ‚Ä¢ Status: {result.get('status', 'success')}")
            emoji_logger.system_info(f"  ‚Ä¢ Tempo total: {total_time:.2f}s")
            emoji_logger.system_info("‚ïê" * 50)
            
            return result
            
        except asyncio.TimeoutError:
            total_time = time.time() - start_time
            emoji_logger.system_error("Multimodal Timeout", f"‚ùå MULTIMODAL: Timeout ap√≥s {MULTIMODAL_TIMEOUT}s")
            emoji_logger.system_info(f"  ‚Ä¢ Tipo: {media_type}")
            emoji_logger.system_info(f"  ‚Ä¢ Tempo decorrido: {total_time:.2f}s")
            
            return {
                "type": media_type,
                "error": f"Processamento excedeu o limite de {MULTIMODAL_TIMEOUT} segundos",
                "status": "timeout",
                "timeout_seconds": MULTIMODAL_TIMEOUT,
                "processing_time": total_time
            }
            
        except Exception as e:
            # Log de erro detalhado
            emoji_logger.system_error("Multimodal Processing", f"Erro ao processar {media_type}: {str(e)[:200]}")
            logger.exception(f"Erro completo no processamento multimodal de {media_type}:")
            
            # M√©tricas finais de erro
            total_time = time.time() - start_time
            emoji_logger.system_info("‚ïê" * 50)
            emoji_logger.system_info(f"‚ùå MULTIMODAL: Processamento falhou")
            emoji_logger.system_info(f"  ‚Ä¢ Tipo: {media_type}")
            emoji_logger.system_info(f"  ‚Ä¢ Erro: {type(e).__name__}")
            emoji_logger.system_info(f"  ‚Ä¢ Mensagem: {str(e)[:100]}")
            emoji_logger.system_info(f"  ‚Ä¢ Tempo total: {total_time:.2f}s")
            emoji_logger.system_info("‚ïê" * 50)
            
            return {
                "type": media_type,
                "error": str(e),
                "status": "error",
                "message": f"Erro ao processar {media_type}",
                "processing_time": total_time
            }
    
    async def search_knowledge_base(
        self,
        query: str,
        filters: Optional[Dict[str, Any]] = None
    ) -> List[Dict[str, Any]]:
        """
        Busca na knowledge base usando KnowledgeService simplificado
        
        Args:
            query: Query de busca
            filters: Filtros opcionais (ignorado na vers√£o simplificada)
            
        Returns:
            Documentos relevantes
        """
        try:
            # Verificar se knowledge base est√° habilitada
            if not self.knowledge_search_enabled:
                return []
                
            emoji_logger.team_knowledge(f"üîç Buscando: {query[:50]}...")
            
            # Usar o novo KnowledgeService simplificado
            results = await knowledge_service.search_knowledge_base(query, max_results=5)
            
            # Converter para formato compat√≠vel
            formatted_results = []
            for doc in results:
                formatted_results.append({
                    "content": doc.get("content", ""),
                    "title": doc.get("title", ""),
                    "category": doc.get("category", ""),
                    "metadata": {
                        "id": doc.get("id"),
                        "tags": doc.get("tags", ""),
                        "created_at": doc.get("created_at", "")
                    },
                    "score": 0.8  # Score fixo para vers√£o simplificada
                })
            
            emoji_logger.team_knowledge(f"‚úÖ Encontrados {len(formatted_results)} documentos")
            return formatted_results
            
        except Exception as e:
            emoji_logger.team_knowledge(f"‚ùå Erro na busca: {e}")
            return []
    
    def analyze_energy_bill(self, image_data: str, customer_name: str = "Cliente") -> Dict[str, Any]:
        """
        Analisa conta de energia via Vision AI - SUBSTITUI BillAnalyzerAgent (881 linhas ‚Üí fun√ß√£o simples)
        
        Args:
            image_data: Imagem em base64
            customer_name: Nome do cliente
            
        Returns:
            Dados extra√≠dos e an√°lise completa
        """
        try:
            # Prompt inteligente que substitui 881 linhas de c√≥digo complexo!
            analysis_prompt = f"""
            Analise esta conta de energia el√©trica e extraia TODOS os dados poss√≠veis.

            EXTRAIR:
            1. Valor total a pagar (R$) - campo mais importante
            2. Consumo em kWh
            3. Nome do titular
            4. Endere√ßo da instala√ß√£o
            5. N√∫mero da instala√ß√£o/UC
            6. Fornecedor (Celpe, Coelba, Cosern, etc)
            7. M√™s de refer√™ncia
            8. Hist√≥rico de consumo se vis√≠vel

            CALCULAR:
            - Economia mensal com solar (20% do valor total)
            - Economia anual (economia mensal √ó 12)
            - Sistema solar recomendado em kWp (consumo √∑ 150)
            - N√∫mero de pain√©is necess√°rios (kWp √∑ 0.55)
            - Investimento estimado (kWp √ó R$ 4.000)
            - Payback em anos (investimento √∑ economia anual)

            QUALIFICAR LEAD:
            - Se valor ‚â• R$ 600: "LEAD_QUENTE" 
            - Se valor ‚â• R$ 400: "IDEAL"
            - Se valor ‚â• R$ 200: "QUALIFICADO"
            - Se valor < R$ 200: "BAIXO"

            RETORNAR JSON ESTRUTURADO com todos os campos calculados.
            """
            
            # Usar Vision AI do Gemini (modelo j√° tem capacidade multimodal)
            import base64
            image_bytes = base64.b64decode(image_data)
            
            # Usar Gemini diretamente via genai (n√£o pelo AGNO)
            import google.generativeai as genai
            genai.configure(api_key=settings.google_api_key)
            
            # Preparar imagem para Gemini
            from PIL import Image
            from io import BytesIO
            img = Image.open(BytesIO(image_bytes))
            
            # Usar modelo Gemini Flash para an√°lise r√°pida
            model = genai.GenerativeModel('gemini-1.5-flash')
            response = model.generate_content([analysis_prompt, img])
            
            # Parse da resposta JSON
            import json
            import re
            from datetime import datetime
            
            # Extrair texto da resposta
            response_text = response.text if hasattr(response, 'text') else str(response)
            json_start = response_text.find('{')
            json_end = response_text.rfind('}') + 1
            
            if json_start >= 0 and json_end > json_start:
                json_str = response_text[json_start:json_end]
                try:
                    result = json.loads(json_str)
                except:
                    # Fallback: extrair manualmente via regex
                    result = self._extract_bill_data_fallback(response_text)
            else:
                result = self._extract_bill_data_fallback(response_text)
            
            # Normalizar campos e garantir dados m√≠nimos
            normalized_result = {
                "success": True,
                "analysis_method": "vision_ai_prompt",
                "customer_name": customer_name,
                "analyzed_at": datetime.now().isoformat(),
                
                # Dados extra√≠dos
                "valor_total": result.get("valor_total") or result.get("bill_value", 0),
                "consumo_kwh": result.get("consumo_kwh") or result.get("consumption_kwh", 0),
                "titular": result.get("titular") or result.get("customer_name", ""),
                "endereco": result.get("endereco") or result.get("address", ""),
                "instalacao": result.get("instalacao") or result.get("installation_number", ""),
                "fornecedor": result.get("fornecedor") or result.get("provider", ""),
                "mes_referencia": result.get("mes_referencia") or result.get("reference_month", ""),
                
                # C√°lculos financeiros
                "economia_mensal": result.get("economia_mensal", 0),
                "economia_anual": result.get("economia_anual", 0),
                "sistema_kwp": result.get("sistema_kwp", 0),
                "num_paineis": result.get("num_paineis", 0),
                "investimento": result.get("investimento", 0),
                "payback_anos": result.get("payback_anos", 0),
                
                # Qualifica√ß√£o
                "qualificacao": result.get("qualificacao", "BAIXO"),
                "qualificado": result.get("valor_total", 0) >= 200
            }
            
            emoji_logger.team_knowledge(f"üí° Conta analisada via Vision AI: R$ {normalized_result.get('valor_total', 0)} - {normalized_result.get('qualificacao', 'N/A')}")
            return normalized_result
            
        except Exception as e:
            logger.error(f"Erro an√°lise conta Vision AI: {e}")
            return {
                "success": False,
                "error": str(e),
                "analysis_method": "vision_ai_prompt",
                "customer_name": customer_name
            }
    
    def _extract_bill_data_fallback(self, text: str) -> Dict[str, Any]:
        """Extra√ß√£o fallback se JSON parsing falhar - regex simples"""
        result = {}
        
        import re
        
        # Valor em R$ - m√∫ltiplos padr√µes
        for pattern in [r'R\$\s*([\d.,]+)', r'total[:\s]+R?\$?\s*([\d.,]+)', r'pagar[:\s]+R?\$?\s*([\d.,]+)']:
            value_match = re.search(pattern, text, re.IGNORECASE)
            if value_match:
                value_str = value_match.group(1).replace('.', '').replace(',', '.')
                try:
                    bill_value = float(value_str)
                    result['valor_total'] = bill_value
                    
                    # C√°lculos b√°sicos
                    result['economia_mensal'] = bill_value * 0.20
                    result['economia_anual'] = result['economia_mensal'] * 12
                    
                    # Qualifica√ß√£o
                    if bill_value >= 600:
                        result['qualificacao'] = 'LEAD_QUENTE'
                    elif bill_value >= 400:
                        result['qualificacao'] = 'IDEAL'
                    elif bill_value >= 200:
                        result['qualificacao'] = 'QUALIFICADO'
                    else:
                        result['qualificacao'] = 'BAIXO'
                    break
                except:
                    continue
        
        # Consumo kWh
        kwh_match = re.search(r'(\d+)\s*kWh', text, re.IGNORECASE)
        if kwh_match:
            consumption = int(kwh_match.group(1))
            result['consumo_kwh'] = consumption
            
            # Dimensionamento aproximado
            if consumption > 0:
                result['sistema_kwp'] = round(consumption / 150, 2)
                result['num_paineis'] = int(result['sistema_kwp'] / 0.55) + 1
                result['investimento'] = result['sistema_kwp'] * 4000
                
                if result.get('economia_anual', 0) > 0:
                    result['payback_anos'] = round(result['investimento'] / result['economia_anual'], 1)
        
        return result
    
    # Fun√ß√µes simples que substituem servi√ßos complexos (456+404=860 linhas ‚Üí ~50 linhas)
    
    def _format_context_simple(
        self,
        message_history: List[Dict[str, Any]] = None,
        multimodal_result: Dict[str, Any] = None,
        phone: str = None
    ) -> Dict[str, Any]:
        """
        Formata√ß√£o SIMPLES de contexto - substitui agno_context_agent.py (456 linhas)
        MANT√âM TODAS as mensagens recuperadas (at√© 100) para preservar contexto completo
        """
        try:
            if not message_history:
                return {
                    'formatted_history': "",
                    'message_count': 0,
                    'context_quality': 'empty'
                }
            
            # Pegar TODAS as mensagens recuperadas (mant√©m as 100 mensagens originais!)
            recent_messages = message_history  # SEM REDU√á√ÉO - usa todas as mensagens que foram buscadas
            
            # Formato simples: "USER: mensagem" ou "ASSISTANT: mensagem"
            formatted_lines = []
            
            # CORRE√á√ÉO CR√çTICA: Incluir an√°lise multimodal PRIMEIRO no contexto
            if multimodal_result and not multimodal_result.get('error'):
                media_type = multimodal_result.get('type', 'unknown')
                content = multimodal_result.get('content', '')
                
                if content:
                    # Adicionar an√°lise multimodal com destaque
                    formatted_lines.append("=== AN√ÅLISE MULTIMODAL RECEBIDA ===")
                    formatted_lines.append(f"TIPO: {media_type.upper()}")
                    formatted_lines.append(f"AN√ÅLISE: {content}")
                    
                    # Se for conta de luz, adicionar detalhes
                    if multimodal_result.get('is_bill'):
                        formatted_lines.append(f"CONTA DE LUZ DETECTADA - Valor: R$ {multimodal_result.get('bill_amount', 0):.2f}")
                    
                    formatted_lines.append("=== FIM DA AN√ÅLISE ===")
                    formatted_lines.append("")  # Linha em branco para separa√ß√£o
            
            # Adicionar hist√≥rico de mensagens
            for msg in recent_messages:
                role = msg.get('sender', 'user').upper()
                content = msg.get('content', '')
                if content:
                    formatted_lines.append(f"{role}: {content}")
            
            return {
                'formatted_history': '\n'.join(formatted_lines),
                'message_count': len(recent_messages),
                'context_quality': 'excellent' if len(recent_messages) >= 50 else 'good' if len(recent_messages) >= 10 else 'basic',
                'has_multimodal': bool(multimodal_result and not multimodal_result.get('error'))
            }
            
        except Exception as e:
            logger.error(f"Erro formata√ß√£o contexto: {e}")
            return {
                'formatted_history': "",
                'message_count': 0,
                'context_quality': 'error'
            }
    
    async def _process_document_simple(self, data: bytes, filename: str = "document") -> Dict[str, Any]:
        """
        Processamento SIMPLES de documentos via Vision AI - substitui document_processor_enhanced.py (404 linhas)
        """
        try:
            import base64
            
            # Converter para base64
            document_b64 = base64.b64encode(data).decode()
            
            # Usar Vision AI diretamente (muito mais simples que OCR/PDF parsing)
            prompt = """
            Analise este documento e extraia:
            1. Tipo de documento
            2. Conte√∫do principal (texto leg√≠vel)
            3. Informa√ß√µes importantes (valores, datas, nomes)
            4. Se for conta de energia: valor total e consumo
            
            Retorne JSON estruturado com os dados extra√≠dos.
            """
            
            # Usar Gemini diretamente para documentos tamb√©m
            import google.generativeai as genai
            genai.configure(api_key=settings.google_api_key)
            
            # Para PDFs, tentar usar como imagem primeiro
            from PIL import Image
            from io import BytesIO
            
            try:
                # Tentar abrir como imagem (para PDFs simples)
                img = Image.open(BytesIO(data))
                model = genai.GenerativeModel('gemini-1.5-flash')
                response = model.generate_content([prompt, img])
                response_text = response.text if hasattr(response, 'text') else str(response)
            except:
                # Se falhar, usar apenas o texto do prompt
                # Por agora, retornar erro estruturado
                return {
                    "success": False,
                    "error": "PDF complexo requer processamento avan√ßado",
                    "document_type": "pdf",
                    "content": "N√£o foi poss√≠vel processar este PDF automaticamente. Por favor, envie uma imagem da conta."
                }
            
            # Parse simples da resposta
            import json
            try:
                json_start = response_text.find('{')
                json_end = response_text.rfind('}') + 1
                if json_start >= 0 and json_end > json_start:
                    result = json.loads(response_text[json_start:json_end])
                else:
                    result = {"text_content": response_text, "document_type": "unknown"}
            except:
                result = {"text_content": response_text, "document_type": "text"}
            
            result.update({
                "success": True,
                "processing_method": "vision_ai_simple",
                "filename": filename
            })
            
            return result
            
        except Exception as e:
            logger.error(f"Erro processamento documento: {e}")
            return {
                "success": False,
                "error": str(e),
                "processing_method": "vision_ai_simple"
            }
    
    # M√©todos auxiliares privados
    def _calculate_duration(self, messages: List[Dict[str, Any]]) -> float:
        """Calcula dura√ß√£o da conversa em horas"""
        if len(messages) < 2:
            return 0
        
        first_msg = datetime.fromisoformat(messages[0]["created_at"])
        last_msg = datetime.fromisoformat(messages[-1]["created_at"])
        
        return (last_msg - first_msg).total_seconds() / 3600
    
    def _analyze_engagement(self, messages: List[Dict[str, Any]]) -> str:
        """Analisa n√≠vel de engajamento do lead"""
        if not messages:
            return "low"
        
        # Calcular m√©tricas de engajamento
        user_messages = [m for m in messages if m.get("sender") == "user"]
        avg_response_length = sum(len(m.get("content", "")) for m in user_messages) / max(len(user_messages), 1)
        response_frequency = len(user_messages) / max(self._calculate_duration(messages), 1)
        
        if avg_response_length > 50 and response_frequency > 2:
            return "high"
        elif avg_response_length > 20 and response_frequency > 1:
            return "medium"
        else:
            return "low"
    
    def _detect_intents(self, messages: List[Dict[str, Any]]) -> List[str]:
        """Detecta inten√ß√µes na conversa"""
        intents = []
        
        intent_keywords = {
            "save_money": ["economizar", "desconto", "reduzir", "conta alta"],
            "install_solar": ["instalar", "pain√©is", "usina", "solar"],
            "get_information": ["como funciona", "informa√ß√µes", "saber mais", "entender"],
            "schedule_meeting": ["reuni√£o", "agendar", "marcar", "conversar"],
            "compare_options": ["diferen√ßa", "comparar", "melhor", "op√ß√µes"]
        }
        
        for msg in messages:
            content = msg.get("content", "").lower()
            for intent, keywords in intent_keywords.items():
                if any(kw in content for kw in keywords) and intent not in intents:
                    intents.append(intent)
        
        return intents
    
    def _analyze_emotional_trajectory(self, messages: List[Dict[str, Any]]) -> str:
        """Analisa trajet√≥ria emocional da conversa"""
        if not messages:
            return "neutral"
        
        # Simplificado: an√°lise das √∫ltimas mensagens
        recent_messages = messages[-10:] if len(messages) > 10 else messages
        
        positive_count = 0
        negative_count = 0
        
        for msg in recent_messages:
            content = msg.get("content", "").lower()
            
            # Palavras positivas
            if any(word in content for word in ["√≥timo", "excelente", "perfeito", "adorei", "sim"]):
                positive_count += 1
            
            # Palavras negativas
            if any(word in content for word in ["n√£o", "dif√≠cil", "caro", "problema", "d√∫vida"]):
                negative_count += 1
        
        if positive_count > negative_count:
            return "positive"
        elif negative_count > positive_count:
            return "negative"
        else:
            return "neutral"
    
    def _extract_key_topics(self, messages: List[Dict[str, Any]]) -> List[str]:
        """Extrai t√≥picos principais da conversa"""
        topics = []
        
        topic_keywords = {
            "pricing": ["pre√ßo", "valor", "custo", "investimento"],
            "savings": ["economia", "desconto", "redu√ß√£o"],
            "contract": ["contrato", "prazo", "fidelidade"],
            "installation": ["instala√ß√£o", "obra", "telhado"],
            "guarantee": ["garantia", "seguran√ßa", "risco"]
        }
        
        for msg in messages:
            content = msg.get("content", "").lower()
            for topic, keywords in topic_keywords.items():
                if any(kw in content for kw in keywords) and topic not in topics:
                    topics.append(topic)
        
        return topics
    
    def _detect_qualification_signals(self, messages: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Detecta sinais de qualifica√ß√£o do lead"""
        signals = {
            "bill_value": 0,
            "has_decision_power": False,
            "timeline_mentioned": False,
            "budget_discussed": False,
            "competitor_mentioned": False
        }
        
        for msg in messages:
            content = msg.get("content", "").lower()
            
            # Detectar valor da conta
            import re
            valores = re.findall(r'r\$?\s*(\d+\.?\d*)', content)
            if valores:
                signals["bill_value"] = max(signals["bill_value"], 
                                           max(float(v.replace(".", "")) for v in valores))
            
            # Detectar poder de decis√£o
            if any(word in content for word in ["eu decido", "sou o respons√°vel", "minha empresa"]):
                signals["has_decision_power"] = True
            
            # Timeline
            if any(word in content for word in ["este m√™s", "urgente", "logo", "quando"]):
                signals["timeline_mentioned"] = True
            
            # Budget
            if any(word in content for word in ["or√ßamento", "investimento", "posso pagar"]):
                signals["budget_discussed"] = True
            
            # Concorr√™ncia
            if any(word in content for word in ["origo", "setta", "outro fornecedor"]):
                signals["competitor_mentioned"] = True
        
        return signals
    
    def _extract_objections(self, messages: List[Dict[str, Any]]) -> List[str]:
        """Extrai obje√ß√µes mencionadas"""
        objections = []
        
        objection_patterns = {
            "price": ["muito caro", "n√£o tenho dinheiro", "fora do or√ßamento"],
            "trust": ["n√£o confio", "√© golpe", "engana√ß√£o"],
            "timing": ["n√£o √© o momento", "depois", "ano que vem"],
            "need": ["n√£o preciso", "n√£o vale a pena", "satisfeito"],
            "competitor": ["j√° tenho", "outro fornecedor", "contrato vigente"]
        }
        
        for msg in messages:
            content = msg.get("content", "").lower()
            for objection_type, patterns in objection_patterns.items():
                if any(p in content for p in patterns) and objection_type not in objections:
                    objections.append(objection_type)
        
        return objections
    
    def _determine_decision_stage(self, messages: List[Dict[str, Any]]) -> str:
        """Determina est√°gio de decis√£o do lead"""
        if len(messages) < 5:
            return "awareness"
        
        # An√°lise simplificada baseada em palavras-chave
        recent_content = " ".join([m.get("content", "") for m in messages[-10:]])
        
        if any(word in recent_content.lower() for word in ["fechado", "vamos fazer", "aceito"]):
            return "decision"
        elif any(word in recent_content.lower() for word in ["quanto", "como funciona", "garantias"]):
            return "consideration"
        elif any(word in recent_content.lower() for word in ["interessante", "me conta mais"]):
            return "interest"
        else:
            return "awareness"
    
    def _assess_urgency(self, messages: List[Dict[str, Any]], current_message: str) -> str:
        """Avalia n√≠vel de urg√™ncia"""
        urgency_keywords = {
            "high": ["urgente", "agora", "hoje", "imediato"],
            "medium": ["esta semana", "breve", "logo"],
            "low": ["futuramente", "talvez", "vou pensar"]
        }
        
        combined_text = current_message.lower() + " " + \
                       " ".join([m.get("content", "") for m in messages[-5:]])
        
        for level, keywords in urgency_keywords.items():
            if any(kw in combined_text for kw in keywords):
                return level
        
        return "medium"
    
    def _determine_primary_context(self, analysis: Dict[str, Any]) -> str:
        """Determina contexto principal da conversa"""
        # L√≥gica de prioriza√ß√£o baseada na an√°lise
        
        if analysis.get("decision_stage") == "decision" and \
           analysis.get("qualification_signals", {}).get("bill_value", 0) > 4000:
            return ConversationContext.SCHEDULING_READY.value
        
        if len(analysis.get("objections_raised", [])) > 1:
            return ConversationContext.OBJECTION_HANDLING.value
        
        if analysis.get("qualification_signals", {}).get("bill_value", 0) > 6000:
            return ConversationContext.HIGH_VALUE_LEAD.value
        
        if analysis.get("lead_engagement_level") == "high" and \
           len(analysis.get("detected_intents", [])) > 2:
            return ConversationContext.QUALIFICATION_NEEDED.value
        
        if "technical" in analysis.get("key_topics", []):
            return ConversationContext.TECHNICAL_QUESTIONS.value
        
        if analysis.get("conversation_duration", 0) > 24:
            return ConversationContext.FOLLOW_UP_REQUIRED.value
        
        return ConversationContext.INITIAL_CONTACT.value
    
    def _recommend_action(self, analysis: Dict[str, Any]) -> str:
        """Recomenda a√ß√£o baseada na an√°lise"""
        context = analysis.get("primary_context")
        
        action_map = {
            ConversationContext.SCHEDULING_READY.value: "Agendar reuni√£o com o consultor",
            ConversationContext.OBJECTION_HANDLING.value: "Tratar obje√ß√µes com empatia e dados",
            ConversationContext.HIGH_VALUE_LEAD.value: "Priorizar atendimento personalizado",
            ConversationContext.QUALIFICATION_NEEDED.value: "Qualificar lead com perguntas-chave",
            ConversationContext.TECHNICAL_QUESTIONS.value: "Fornecer informa√ß√µes t√©cnicas detalhadas",
            ConversationContext.FOLLOW_UP_REQUIRED.value: "Reengajar com oferta especial",
            ConversationContext.INITIAL_CONTACT.value: "Iniciar rapport e descobrir necessidades"
        }
        
        return action_map.get(context, "Continuar conversa naturalmente")
    
    async def initialize(self):
        """Inicializa recursos do agente com fallback robusto"""
        try:
            # Carregar knowledge base do SUPABASE (n√£o de arquivos locais!)
            await self._load_knowledge_from_supabase()
            
            # Inicializar SDR Team se necess√°rio (com fallback)
            try:
                if not self.sdr_team:
                    from app.teams.sdr_team import create_sdr_team
                    self.sdr_team = create_sdr_team()
                    await self.sdr_team.initialize()
                    emoji_logger.system_ready("SDR Team inicializado")
            except Exception as team_error:
                emoji_logger.system_warning(f"SDR Team n√£o inicializado: {str(team_error)[:50]}")
                self.sdr_team = None
                # Continuar sem SDR Team
            
            self.is_initialized = True
            emoji_logger.system_ready("AGENTIC SDR", startup_time=0.5)
            
        except Exception as e:
            emoji_logger.system_error("AGENTIC SDR", f"Erro cr√≠tico na inicializa√ß√£o: {e}")
            # Marcar como inicializado mesmo com erro para permitir funcionamento b√°sico
            self.is_initialized = True
    
    async def _load_knowledge_from_supabase(self):
        """Carrega knowledge base diretamente do Supabase"""
        try:
            if not self.knowledge:
                emoji_logger.system_warning("AgentKnowledge n√£o dispon√≠vel - pulando carregamento")
                return
            
            emoji_logger.system_info("Carregando knowledge base do Supabase...")
            
            # Buscar documentos da tabela knowledge_base (usando import global)
            
            # Query para buscar todos os documentos ativos
            result = supabase_client.client.table("knowledge_base").select("*").execute()
            
            if result.data and len(result.data) > 0:
                # Processar cada documento
                docs_loaded = 0
                for doc in result.data:
                    try:
                        # Extrair campos do documento
                        doc_id = doc.get("id")
                        title = doc.get("title", "")
                        content = doc.get("content", "")
                        category = doc.get("category", "")
                        tags = doc.get("tags", [])
                        
                        # Verificar se tem conte√∫do
                        if not content:
                            continue
                        
                        # Criar texto formatado para o knowledge base
                        formatted_text = f"""
                        T√≠tulo: {title}
                        Categoria: {category}
                        Tags: {', '.join(tags) if tags else 'N/A'}
                        
                        {content}
                        """
                        
                        # Adicionar ao knowledge base usando m√©todo correto
                        if hasattr(self.knowledge, 'load_text'):
                            self.knowledge.load_text(
                                text=formatted_text,
                                metadata={
                                    "id": doc_id,
                                    "title": title,
                                    "category": category,
                                    "tags": tags,
                                    "source": "supabase"
                                }
                            )
                            docs_loaded += 1
                        elif hasattr(self.knowledge, 'add'):
                            self.knowledge.add(
                                text=formatted_text,
                                metadata={
                                    "id": doc_id,
                                    "title": title,
                                    "category": category,
                                    "tags": tags,
                                    "source": "supabase"
                                }
                            )
                            docs_loaded += 1
                            
                    except Exception as doc_error:
                        emoji_logger.system_warning(f"Erro ao carregar doc {doc.get('id')}: {str(doc_error)[:50]}")
                        continue
                
                emoji_logger.system_ready(f"Knowledge base carregada do Supabase", 
                                        documents_loaded=docs_loaded,
                                        total_documents=len(result.data))
            else:
                emoji_logger.system_warning("Nenhum documento encontrado na knowledge_base do Supabase")
                
        except Exception as e:
            emoji_logger.system_error("Knowledge Base Loader", f"Erro ao carregar do Supabase: {str(e)[:100]}")
            # N√£o lan√ßar erro - continuar sem knowledge base
    
    def _generate_simple_fallback_response(self, message: str) -> str:
        """Gera resposta simples de fallback quando agent.arun falha ou d√° timeout"""
        
        emoji_logger.system_info("üîÑ Gerando resposta de fallback...")
        
        # Respostas contextuais baseadas em palavras-chave
        message_lower = message.lower()
        
        if any(word in message_lower for word in ['oi', 'ol√°', 'ola', 'bom dia', 'boa tarde', 'boa noite']):
            return "Oi! Vi sua mensagem sobre energia solar. Voc√™ gostaria de saber quanto pode economizar na sua conta de luz?"
        
        elif any(word in message_lower for word in ['quanto', 'valor', 'pre√ßo', 'preco', 'custa']):
            return "Para calcular sua economia, preciso saber: qual o valor m√©dio da sua conta de luz?"
        
        elif any(word in message_lower for word in ['economia', 'economizar', 'desconto']):
            return "Com energia solar voc√™ pode economizar at√© 95% na conta de luz! Qual o valor da sua conta atual?"
        
        elif any(word in message_lower for word in ['sim', 'quero', 'tenho interesse']):
            return "√ìtimo! Para fazer uma proposta personalizada, me diz: quanto voc√™ paga de luz por m√™s?"
        
        elif any(word in message_lower for word in ['n√£o', 'nao', 'depois', 'agora n√£o']):
            return "Sem problemas! Quando quiser saber mais sobre energia solar, estarei aqui. At√© mais!"
        
        else:
            # Resposta gen√©rica
            return "Entendi! Para te ajudar melhor com energia solar, qual o valor da sua conta de luz?"
    
    def _extract_name(self, message: str) -> Optional[str]:
        """Extrai nome do lead da mensagem usando regex simples"""
        patterns = [
            r"meu nome √© ([A-Z][a-zA-Z]+(?: [A-Z][a-zA-Z]+)*)",
            r"me chamo ([A-Z][a-zA-Z]+(?: [A-Z][a-zA-Z]+)*)",
            r"sou o?a? ([A-Z][a-zA-Z]+(?: [A-Z][a-zA-Z]+)*)",
            r"([A-Z][a-zA-Z]+(?: [A-Z][a-zA-Z]+)*), prazer"
        ]
        
        for pattern in patterns:
            match = re.search(pattern, message, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        return None
    
    def _extract_email(self, message: str) -> Optional[str]:
        """Extrai email do lead usando regex"""
        pattern = r'\b[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}\b'
        match = re.search(pattern, message)
        
        if match:
            return match.group(0).lower()
        
        return None
    
    def _extract_document(self, message: str) -> Optional[str]:
        """Extrai CPF ou CNPJ da mensagem"""
        # Remove pontua√ß√£o para facilitar
        clean_msg = re.sub(r'[.\-/]', '', message)
        
        # CPF: 11 d√≠gitos
        cpf_pattern = r'\b\d{11}\b'
        cpf_match = re.search(cpf_pattern, clean_msg)
        if cpf_match:
            cpf = cpf_match.group(0)
            # Formata CPF: XXX.XXX.XXX-XX
            return f"{cpf[:3]}.{cpf[3:6]}.{cpf[6:9]}-{cpf[9:]}"
        
        # CNPJ: 14 d√≠gitos
        cnpj_pattern = r'\b\d{14}\b'
        cnpj_match = re.search(cnpj_pattern, clean_msg)
        if cnpj_match:
            cnpj = cnpj_match.group(0)
            # Formata CNPJ: XX.XXX.XXX/XXXX-XX
            return f"{cnpj[:2]}.{cnpj[2:5]}.{cnpj[5:8]}/{cnpj[8:12]}-{cnpj[12:]}"
        
        return None
    
    def _extract_bill_value(self, message: str) -> Optional[float]:
        """Extrai valor da conta de luz da mensagem"""
        import re
        
        # Padr√µes para detectar valores em reais
        # Ex: R$ 4.000, R$4000, 4000 reais, 4.000,00
        patterns = [
            r'r\$?\s*(\d{1,3}(?:\.\d{3})*(?:,\d{2})?)',  # R$ 4.000,00
            r'(\d{1,3}(?:\.\d{3})*(?:,\d{2})?)\s*reais',  # 4.000 reais
            r'conta.*?(\d{1,3}(?:\.\d{3})*)',  # conta de 4.000
            r'valor.*?(\d{1,3}(?:\.\d{3})*)',  # valor 4.000
        ]
        
        message_lower = message.lower()
        
        for pattern in patterns:
            matches = re.findall(pattern, message_lower, re.IGNORECASE)
            if matches:
                for match in matches:
                    try:
                        # Remove pontos de milhar e substitui v√≠rgula por ponto
                        value_str = match.replace('.', '').replace(',', '.')
                        value = float(value_str)
                        
                        # Se o valor parece ser da conta de luz (entre 100 e 50000)
                        if 100 <= value <= 50000:
                            return value
                    except ValueError:
                        continue
        
        return None
    
    def _calculate_qualification_score(self, lead_data: Dict) -> int:
        """Calcula score de qualifica√ß√£o baseado nos dados do lead"""
        score = 0
        
        # Score baseado no valor da conta (m√°ximo 50 pontos)
        bill_value = lead_data.get('bill_value', 0) or 0
        if bill_value >= 8000:
            score += 50  # Conta muito alta
        elif bill_value >= 6000:
            score += 40  # Conta alta
        elif bill_value >= 4000:
            score += 30  # Conta qualificada
        elif bill_value >= 2000:
            score += 20  # Conta m√©dia
        elif bill_value >= 500:
            score += 10  # Conta baixa mas v√°lida
        
        # Score baseado em tomada de decis√£o (20 pontos)
        if lead_data.get('is_decision_maker'):
            score += 20
        
        # Score baseado em interesse (15 pontos)
        if lead_data.get('has_interest'):
            score += 15
        
        # Score baseado em n√£o ter sistema solar (10 pontos)
        if not lead_data.get('has_solar_system'):
            score += 10
        
        # Score baseado em n√£o ter contrato ativo (5 pontos)  
        if not lead_data.get('has_active_contract'):
            score += 5
        
        # Garantir que o score n√£o ultrapasse 100
        return min(score, 100)
    
    def _identify_stage(self, message: str, lead_data: Dict) -> str:
        """Identifica est√°gio atual baseado na conversa e dados do lead"""
        
        message_lower = message.lower()
        
        # Verificar se est√° qualificado
        if lead_data:
            # Corrigir compara√ß√£o com None - garantir que bill_value √© um n√∫mero
            bill_value = lead_data.get('bill_value')
            if bill_value is None:
                bill_value = 0
            else:
                # Converter para float se for string
                try:
                    bill_value = float(bill_value) if bill_value else 0
                except (ValueError, TypeError):
                    bill_value = 0
            
            qualificado = all([
                bill_value > 4000,
                lead_data.get('is_decision_maker') == True,
                lead_data.get('has_solar_system') == False or lead_data.get('wants_new_solar_system') == True,
                lead_data.get('has_active_contract') == False
            ])
            
            if qualificado:
                return "QUALIFICADO"
        
        # Identificar por palavras-chave
        if any(word in message_lower for word in ["agendar", "reuni√£o", "marcar", "disponibilidade", "hor√°rio"]):
            return "REUNIAO_AGENDADA"
        
        elif any(word in message_lower for word in ["quanto custa", "valor", "pre√ßo", "investimento", "or√ßamento"]):
            return "EM_NEGOCIACAO"
        
        elif any(phrase in message_lower for phrase in ["n√£o tenho interesse", "n√£o quero", "obrigado mas", "desisto"]):
            return "NAO_INTERESSADO"
        
        elif any(word in message_lower for word in ["conta de luz", "energia", "consumo", "kwh"]):
            return "EM_QUALIFICACAO"
        
        # Se n√£o identificou, mant√©m o atual ou usa default
        return lead_data.get('current_stage', 'EM_QUALIFICACAO') if lead_data else "INITIAL_CONTACT"
    
    async def process_message(
        self,
        phone: str,
        message: str,
        lead_data: Optional[Dict[str, Any]] = None,
        conversation_id: Optional[str] = None,
        media: Optional[Dict[str, Any]] = None,
        message_id: Optional[str] = None,
        current_emotional_state: Optional[str] = None
    ) -> str:
        """
        Processa mensagem com an√°lise contextual inteligente
        
        Args:
            phone: N√∫mero do telefone
            message: Mensagem recebida
            lead_data: Dados do lead
            conversation_id: ID da conversa
            media: M√≠dia anexada
            
        Returns:
            Resposta do AGENTIC SDR
        """
        # Inicializar response para evitar erro de vari√°vel n√£o definida
        response = None
        
        # DEFENSIVE PROGRAMMING: Inicializar new_emotional_state com valor padr√£o seguro
        new_emotional_state = current_emotional_state or "ENTUSIASMADA"
        
        try:
            emoji_logger.agentic_thinking(f"Processando mensagem de {phone}: {message[:50]}...")
            
            if not self.is_initialized:
                await self.initialize()
            
            # EXTRA√á√ÉO DE DADOS E ATUALIZA√á√ÉO DE EST√ÅGIO
            # Extrair informa√ß√µes b√°sicas da mensagem
            nome_extraido = self._extract_name(message)
            email_extraido = self._extract_email(message)
            documento_extraido = self._extract_document(message)
            bill_value_extraido = self._extract_bill_value(message)
            
            # Identificar novo est√°gio
            novo_stage = self._identify_stage(message, lead_data or {})
            
            # Preparar dados para atualiza√ß√£o
            update_data = {}
            if nome_extraido and (not lead_data or not lead_data.get('name')):
                update_data['name'] = nome_extraido
                emoji_logger.system_info(f"Nome extra√≠do: {nome_extraido}")
            
            if email_extraido and (not lead_data or not lead_data.get('email')):
                update_data['email'] = email_extraido
                emoji_logger.system_info(f"Email extra√≠do: {email_extraido}")
            
            if documento_extraido and (not lead_data or not lead_data.get('document')):
                update_data['document'] = documento_extraido
                emoji_logger.system_info(f"Documento extra√≠do: {documento_extraido}")
            
            if bill_value_extraido and (not lead_data or not lead_data.get('bill_value')):
                update_data['bill_value'] = bill_value_extraido
                emoji_logger.system_info(f"üí∞ Valor da conta extra√≠do: R$ {bill_value_extraido}")
            
            if lead_data and novo_stage != lead_data.get('current_stage'):
                update_data['current_stage'] = novo_stage
                emoji_logger.system_info(f"Novo est√°gio identificado: {novo_stage}")
                
                # CORRE√á√ÉO AT√îMICA: Se o lead foi qualificado, calcular e salvar score junto
                if novo_stage == "QUALIFICADO" and not lead_data.get('qualification_status'):
                    # Calcular score baseado nos crit√©rios
                    qualification_score = self._calculate_qualification_score(lead_data)
                    
                    update_data['qualification_status'] = 'QUALIFIED'
                    update_data['qualification_score'] = qualification_score
                    emoji_logger.system_success(f"üéØ Lead qualificado com score {qualification_score}")
                    
                    # Salvar tamb√©m na tabela de qualifica√ß√µes
                    try:
                        await supabase_client.create_lead_qualification({
                            'lead_id': lead_data['id'],
                            'qualification_status': 'QUALIFIED',
                            'score': qualification_score,
                            'criteria': {
                                'bill_value': lead_data.get('bill_value', 0),
                                'is_decision_maker': lead_data.get('is_decision_maker', True),
                                'has_interest': True,
                                'stage_identified': novo_stage
                            },
                            'notes': 'Lead qualificado automaticamente pelo AgenticSDR'
                        })
                        emoji_logger.system_success("‚úÖ Qualifica√ß√£o salva na tabela leads_qualifications")
                    except Exception as qual_error:
                        emoji_logger.system_error("AGENTIC SDR", f"Erro ao salvar qualifica√ß√£o: {qual_error}")
            
            # Atualizar no banco se houver mudan√ßas
            if update_data and lead_data and lead_data.get('id'):
                try:
                    await supabase_client.update_lead(lead_data['id'], update_data)
                    emoji_logger.system_success(f"‚úÖ Lead atualizado no Supabase: {update_data}")
                    
                    # Atualizar lead_data local para uso posterior
                    lead_data.update(update_data)
                except Exception as update_error:
                    emoji_logger.system_warning(f"Erro ao atualizar lead: {str(update_error)[:50]}")
            
            # 1. Tentar an√°lise contextual (com fallback)
            try:
                # Verificar se a fun√ß√£o est√° dispon√≠vel e √© callable
                if hasattr(self, 'analyze_conversation_context') and callable(self.analyze_conversation_context):
                    context_analysis = await self.analyze_conversation_context(phone, message)
                else:
                    raise AttributeError("analyze_conversation_context n√£o est√° dispon√≠vel")
            except Exception as ctx_error:
                emoji_logger.system_warning(f"An√°lise contextual falhou: {str(ctx_error)}")
                # Fallback para contexto b√°sico
                context_analysis = {
                    "primary_context": ConversationContext.INITIAL_CONTACT.value,
                    "lead_engagement_level": "medium",
                    "decision_stage": "awareness",
                    "recommended_action": "Continuar conversa naturalmente"
                }
            
            # 2. Detectar gatilhos emocionais e obter hist√≥rico (com fallback)
            messages_history = []
            try:
                # VALIDA√á√ÉO CR√çTICA: Garantir que conversation_id √© v√°lido
                if not conversation_id:
                    emoji_logger.system_error("HIST√ìRICO", f"‚ùå conversation_id √© None/vazio! Lead: {lead_data}")
                    # Tentar buscar por phone como fallback
                    if phone:
                        emoji_logger.system_info(f"üîÑ Tentando buscar hist√≥rico por phone: {phone}")
                        messages_history = await self.get_last_100_messages(phone)
                    else:
                        emoji_logger.system_error("HIST√ìRICO", "‚ùå Nem conversation_id nem phone dispon√≠veis!")
                        messages_history = []
                else:
                    # Buscar hist√≥rico de mensagens (ser√° usado para contexto e an√°lise emocional)
                    messages_history = await self.get_last_100_messages(conversation_id)
                
                emoji_logger.system_info(f"‚úÖ HIST√ìRICO FINAL: {len(messages_history)} mensagens carregadas")
                emotional_triggers = await self.detect_emotional_triggers(messages_history)
            except Exception as emo_error:
                emoji_logger.system_warning(f"An√°lise emocional falhou: {str(emo_error)[:50]}")
                emotional_triggers = {"dominant_emotion": "neutral", "enabled": False}
            
            # 3. Processar multimodal se necess√°rio
            multimodal_result = None
            if media:
                # Mapear mimetype para type (O SIMPLES FUNCIONA!)
                media_type = self._get_media_type_from_mimetype(media.get("mimetype", ""))
                multimodal_result = await self.process_multimodal_content(
                    media_type,
                    media.get("data", ""),
                    media.get("caption")
                )
                
                # Adicionar ao contexto
                context_analysis["has_media"] = True
                context_analysis["media_analysis"] = multimodal_result
            
            # 4. Decidir inteligentemente sobre SDR Team (com fallback)
            try:
                should_call, recommended_agent, reasoning = await self.should_call_sdr_team(
                    context_analysis,
                    message
                )
            except Exception as decision_error:
                emoji_logger.system_warning(f"Decis√£o SDR Team falhou: {str(decision_error)[:50]}")
                should_call = False
                recommended_agent = None
                reasoning = "Processamento direto devido a erro"
            
            # 5. Se precisar do SDR Team E contexto justificar
            if should_call and recommended_agent and self.sdr_team:
                try:
                    emoji_logger.team_delegate(recommended_agent, reasoning)
                    
                    # Preparar contexto enriquecido para o Team
                    enriched_context = {
                        "phone": phone,
                        "message": message,
                        "lead_data": lead_data,
                        "conversation_id": conversation_id,
                        "context_analysis": context_analysis,
                        "emotional_triggers": emotional_triggers,
                        "recommended_agent": recommended_agent,
                        "reasoning": reasoning,
                        "multimodal_result": multimodal_result
                    }
                    
                    # Chamar SDR Team com contexto completo
                    team_response = await self.sdr_team.process_message_with_context(
                        enriched_context
                    )
                    
                    # AGENTIC SDR ainda personaliza a resposta final
                    response = await self._personalize_team_response(
                        team_response,
                        emotional_triggers,
                        new_emotional_state
                    )
                except Exception as team_error:
                    emoji_logger.system_warning(f"SDR Team falhou: {str(team_error)[:50]}")
                    # Fallback para resposta direta
                    response = None
                
            # Se n√£o tem resposta do Team ou n√£o chamou Team
            if not response:
                # 6. AGENTIC SDR resolve sozinha (90% dos casos)
                emoji_logger.agentic_thinking("Processando mensagem diretamente")
                
                try:
                    # Formatar contexto com fun√ß√£o SIMPLES (substitui agno_context_agent.py)
                    context_result = self._format_context_simple(
                        message_history=messages_history or [],
                        multimodal_result=multimodal_result,
                        phone=phone
                    )
                    
                    # AGNO Framework j√° formatou multimodal + hist√≥rico no formatted_history
                    formatted_history = context_result.get('formatted_history', '')
                    
                    # DEBUG: Verificar se multimodal foi inclu√≠do no contexto
                    if context_result.get('has_multimodal'):
                        emoji_logger.system_info("‚úÖ An√°lise multimodal inclu√≠da no contexto formatado")
                        emoji_logger.system_debug(f"Primeiras 500 chars do contexto: {formatted_history[:500]}...")
                    
                    # Preparar prompt com contexto completo AGNO-enhanced
                    contextual_prompt = f"""
                    CONTEXTO DO LEAD:
                    - Nome: {lead_data.get('name', 'N√£o informado') if lead_data else 'N√£o informado'}
                    - Telefone: {phone}
                    - Est√°gio: {lead_data.get('current_stage', 'INITIAL_CONTACT') if lead_data else 'INITIAL_CONTACT'}
                    - Status: {lead_data.get('qualification_status', 'PENDING') if lead_data else 'PENDING'}
                    
                    {formatted_history}
                    
                    MENSAGEM ATUAL DO CLIENTE: {message}
                    """
                    
                    # Se tem resultado multimodal, adicionar informa√ß√µes EXPLICITAMENTE
                    if multimodal_result and not multimodal_result.get('error'):
                        media_type = multimodal_result.get('type')
                        
                        if media_type == 'audio' and multimodal_result.get('transcription'):
                            contextual_prompt += f"""
                    
                    üé§ TRANSCRI√á√ÉO DO √ÅUDIO RECEBIDO:
                    "{multimodal_result.get('transcription')}"
                    (Dura√ß√£o: {multimodal_result.get('duration', 0)}s)
                    
                    IMPORTANTE: Use a transcri√ß√£o acima como o conte√∫do real da mensagem do cliente, n√£o a mensagem gen√©rica.
                    """
                        
                        elif media_type in ['image', 'bill_image']:  # CORRE√á√ÉO: Aceitar bill_image
                            contextual_prompt += f"""
                    
                    üì∏ IMAGEM RECEBIDA - AN√ÅLISE:
                    {multimodal_result.get('content', 'An√°lise n√£o dispon√≠vel')}
                    
                    """
                            # CORRE√á√ÉO: Verificar tanto is_bill quanto type=='bill_image'
                            if multimodal_result.get('is_bill') or multimodal_result.get('type') == 'bill_image':
                                contextual_prompt += f"""
                    üí° CONTA DE LUZ DETECTADA:
                    - Valor mensal: R$ {multimodal_result.get('bill_amount', 0):.2f}
                    - Consumo: {multimodal_result.get('consumption', 'N/A')} kWh
                    - Concession√°ria: {multimodal_result.get('provider', 'N/A')}
                    """
                        
                        elif media_type == 'pdf':
                            contextual_prompt += f"""
                    
                    üìÑ DOCUMENTO PDF RECEBIDO:
                    Arquivo: {multimodal_result.get('filename', 'documento.pdf')}
                    
                    Conte√∫do extra√≠do:
                    {multimodal_result.get('content', 'Conte√∫do n√£o dispon√≠vel')[:1000]}
                    """
                            if len(multimodal_result.get('content', '')) > 1000:
                                contextual_prompt += "\n[... documento truncado para contexto]"
                    
                    contextual_prompt += f"""
                    
                    An√°lise Contextual:
                    - Contexto Principal: {context_analysis.get('primary_context')}
                    - Engajamento: {context_analysis.get('lead_engagement_level')}
                    - Est√°gio: {context_analysis.get('decision_stage')}
                    - A√ß√£o Recomendada: {context_analysis.get('recommended_action')}
                    
                    Estado Emocional do Lead:
                    - Emo√ß√£o Dominante: {emotional_triggers.get('dominant_emotion')}
                    - Urg√™ncia: {context_analysis.get('urgency_level')}
                    
                    IMPORTANTE: Se uma an√°lise de imagem foi fornecida acima, USE ESSAS INFORMA√á√ïES NA SUA RESPOSTA!
                    Por exemplo, se detectamos uma conta de luz com valor, MENCIONE O VALOR DETECTADO.
                    
                    Responda de forma natural, emp√°tica e personalizada, levando em conta todo o contexto e hist√≥rico da conversa.
                    """
                    
                    # Usar reasoning APENAS para casos complexos
                    # Determinar se a mensagem atual √© complexa
                    is_complex = self._is_complex_message(message)
                    
                    # Debug: Log do prompt sendo enviado
                    emoji_logger.system_info(f"üìù Prompt para o agente (primeiros 500 chars): {contextual_prompt[:500]}...")
                    emoji_logger.system_info(f"üìè Tamanho do prompt: {len(contextual_prompt)} caracteres")
                    
                    # Debug: Verificar se multimodal foi inclu√≠do
                    if multimodal_result and 'content' in multimodal_result:
                        emoji_logger.system_info(f"‚úÖ Multimodal inclu√≠do no prompt: {multimodal_result.get('content', '')[:200]}...")
                    else:
                        emoji_logger.system_info("‚ùå Nenhum resultado multimodal inclu√≠do no prompt")
                    
                    # Debug adicional: verificar se multimodal_result foi inclu√≠do
                    if multimodal_result and not multimodal_result.get('error'):
                        emoji_logger.system_info(f"üñºÔ∏è Multimodal inclu√≠do no prompt: tipo={multimodal_result.get('type')}, tem conte√∫do={bool(multimodal_result.get('content'))}")
                    
                    # Timeout para evitar travamento
                    AGENT_TIMEOUT = 30  # segundos
                    
                    if self.reasoning_enabled and is_complex:
                        emoji_logger.agentic_thinking(f"Mensagem complexa detectada, ativando reasoning mode")
                        # Usar reasoning model para perguntas complexas
                        try:
                            emoji_logger.system_info(f"üöÄ Chamando agent.arun com timeout de {AGENT_TIMEOUT}s (modo complexo)...")
                            if hasattr(self, 'reasoning_model'):
                                result = await asyncio.wait_for(
                                    self.agent.arun(contextual_prompt),
                                    timeout=AGENT_TIMEOUT
                                )
                            else:
                                result = await asyncio.wait_for(
                                    self.agent.arun(contextual_prompt),
                                    timeout=AGENT_TIMEOUT
                                )
                            emoji_logger.system_info("‚úÖ agent.arun completou com sucesso (modo complexo)")
                        except asyncio.TimeoutError:
                            emoji_logger.system_error("Agent Timeout", f"‚ùå Timeout em agent.arun ap√≥s {AGENT_TIMEOUT}s (modo complexo)")
                            result = None
                        except Exception as e:
                            emoji_logger.system_error("Agent Error", f"‚ùå Erro em agent.arun (modo complexo): {str(e)}")
                            result = None
                    else:
                        # Mensagem simples - resposta direta sem reasoning
                        emoji_logger.agentic_thinking(f"Mensagem simples, resposta direta")
                        
                        # Debug: Log antes de chamar o agente
                        emoji_logger.system_info("üöÄ Preparando para chamar agent.arun...")
                        emoji_logger.system_info(f"üìù Agent tem instructions? {bool(self.agent.instructions)}")
                        emoji_logger.system_info(f"üìù Agent tem memory? {bool(self.agent.memory)}")
                        emoji_logger.system_info(f"üìù Agent tem model? {bool(self.agent.model)}")
                        
                        try:
                            emoji_logger.system_info(f"üöÄ Chamando agent.arun com timeout de {AGENT_TIMEOUT}s...")
                            
                            # PROTE√á√ÉO EXTRA: Verificar se agent est√° pronto
                            if not self.agent or not hasattr(self.agent, 'arun'):
                                emoji_logger.system_error("Agent State", "‚ùå Agent n√£o est√° pronto ou n√£o tem m√©todo arun")
                                result = self._generate_simple_fallback_response(message)
                            else:
                                # Criar task para poder cancelar se necess√°rio
                                agent_task = asyncio.create_task(self.agent.arun(contextual_prompt))
                                
                                try:
                                    result = await asyncio.wait_for(agent_task, timeout=AGENT_TIMEOUT)
                                    emoji_logger.system_info("‚úÖ agent.arun completou com sucesso")
                                except asyncio.TimeoutError:
                                    # Cancelar task se ainda estiver rodando
                                    agent_task.cancel()
                                    try:
                                        await agent_task
                                    except asyncio.CancelledError:
                                        pass
                                    raise
                        except asyncio.TimeoutError:
                            emoji_logger.system_error("Agent Timeout", f"‚ùå Timeout em agent.arun ap√≥s {AGENT_TIMEOUT}s")
                            # Tentar gerar resposta de fallback
                            try:
                                emoji_logger.system_info("üîÑ Tentando gerar resposta de fallback...")
                                result = self._generate_simple_fallback_response(message)
                            except Exception as fallback_error:
                                emoji_logger.system_error("Fallback Error", f"‚ùå Falha no fallback: {str(fallback_error)}")
                                result = None
                        except Exception as arun_error:
                            emoji_logger.system_error("Agent Error", f"‚ùå Erro em agent.arun: {str(arun_error)}")
                            import traceback
                            emoji_logger.system_error("Stack Trace", f"Stack trace: {traceback.format_exc()}")
                            result = None
                    
                    # Debug: Log do resultado recebido
                    emoji_logger.system_info(f"üîç Tipo do result: {type(result)}")
                    emoji_logger.system_info(f"üîç result tem content? {hasattr(result, 'content')}")
                    if hasattr(result, '__dict__'):
                        emoji_logger.system_info(f"üîç Atributos do result: {list(result.__dict__.keys())}")
                    else:
                        emoji_logger.system_info(f"üîç result como string: {str(result)[:200]}...")
                    
                    # Debug adicional para entender o resultado
                    if result:
                        emoji_logger.system_info(f"üìã Result n√£o √© None, tipo: {type(result).__name__}")
                    else:
                        emoji_logger.system_warning("‚ö†Ô∏è Result √© None ou vazio!")
                    
                    # Extrair conte√∫do da resposta - CORRE√á√ÉO PARA AGNO RunResponse
                    raw_response = None
                    
                    # 1. Tentar content primeiro
                    if hasattr(result, 'content') and result.content:
                        raw_response = result.content
                    # 2. Se vazio, verificar messages (AGNO padr√£o)
                    elif hasattr(result, 'messages') and result.messages:
                        for msg in reversed(result.messages):
                            if hasattr(msg, 'role') and msg.role == 'assistant' and hasattr(msg, 'content'):
                                raw_response = msg.content
                                emoji_logger.system_info(f"‚úÖ Conte√∫do extra√≠do de messages")
                                break
                    # 3. Outros atributos
                    elif hasattr(result, 'text') and result.text:
                        raw_response = result.text
                    elif hasattr(result, 'message') and result.message:
                        raw_response = result.message
                    elif isinstance(result, dict):
                        raw_response = result.get('content') or result.get('text') or str(result)
                    else:
                        raw_response = str(result)
                    
                    # Debug: Log do conte√∫do extra√≠do
                    emoji_logger.system_info(f"üìÑ raw_response (primeiros 200 chars): {raw_response[:200] if raw_response else 'VAZIO'}...")
                    emoji_logger.system_info(f"üìè Tamanho raw_response: {len(raw_response) if raw_response else 0} caracteres")
                    
                    # Verificar se resposta est√° vazia antes de processar
                    if not raw_response or str(raw_response).strip() == "":
                        emoji_logger.system_warning("‚ö†Ô∏è raw_response est√° vazio ANTES da verifica√ß√£o!")
                    
                    # ‚úÖ CORRE√á√ÉO: Verificar se a resposta est√° vazia antes de processar
                    if not raw_response or raw_response.strip() == "":
                        emoji_logger.system_warning("‚ö†Ô∏è Agent retornou resposta vazia! Usando fallback...")
                        
                        # Debug: Entender por que est√° vazio
                        if multimodal_result and 'content' in multimodal_result and not multimodal_result.get('error'):
                            emoji_logger.system_info("üîç Tinha an√°lise multimodal mas agente retornou vazio")
                            emoji_logger.system_info(f"üîç An√°lise multimodal: {multimodal_result.get('content', '')[:100]}...")
                            
                            # Fallback especializado para quando h√° an√°lise multimodal
                            if multimodal_result.get('is_bill'):
                                # √â uma conta de luz
                                bill_amount = multimodal_result.get('bill_amount', 0)
                                if bill_amount > 0:
                                    raw_response = f"Perfeito! Vi aqui sua conta de luz no valor de R$ {bill_amount:.2f}. Com esse valor, consigo fazer uma an√°lise bem precisa de quanto voc√™ pode economizar com energia solar! Esse valor est√° pesando no or√ßamento?"
                                else:
                                    raw_response = "√ìtimo! Recebi a foto da sua conta de luz. Para fazer uma an√°lise precisa da economia, voc√™ pode me dizer qual o valor m√©dio que est√° pagando?"
                            elif multimodal_result.get('type') == 'image':
                                # Imagem gen√©rica
                                raw_response = "Legal! Recebi sua imagem. Para eu fazer uma proposta personalizada de economia com energia solar, me conta: qual o valor m√©dio da sua conta de luz?"
                            elif multimodal_result.get('type') == 'audio':
                                # √Åudio transcrito
                                transcription = multimodal_result.get('transcription', '')
                                if transcription:
                                    raw_response = f"Entendi! Ouvi seu √°udio dizendo: '{transcription[:100]}...'. Como posso ajudar voc√™ com energia solar?"
                                else:
                                    raw_response = "Recebi seu √°udio! Para fazer uma an√°lise completa, preciso saber: qual o valor da sua conta de luz?"
                            else:
                                # Fallback gen√©rico com m√≠dia
                                raw_response = "Obrigada por enviar! Para fazer uma proposta personalizada de economia, preciso saber o valor da sua conta de luz. Quanto voc√™ paga em m√©dia?"
                        else:
                            emoji_logger.system_info("üîç Sem an√°lise multimodal dispon√≠vel")
                            # Fallback com base no est√°gio atual
                            current_stage = lead_data.get('current_stage', 'INITIAL_CONTACT') if lead_data else 'INITIAL_CONTACT'
                            if current_stage == 'INITIAL_CONTACT':
                                raw_response = "Oi! Tudo bem? Sou a Helen da SolarPrime! Antes de come√ßarmos, como posso te chamar?"
                            else:
                                raw_response = "Oi! Desculpe, tive um probleminha aqui. Pode repetir sua √∫ltima mensagem?"
                    
                    # ‚úÖ CORRE√á√ÉO: Verificar se j√° h√° tags antes de adicionar (evita duplica√ß√£o)
                    if "<RESPOSTA_FINAL>" in raw_response:
                        # Resposta j√° tem tags - usar diretamente
                        response = raw_response
                        emoji_logger.system_debug("‚úÖ Tags <RESPOSTA_FINAL> j√° presentes - usando resposta diretamente")
                    else:
                        # Resposta sem tags - adicionar tags para extra√ß√£o
                        response = f"<RESPOSTA_FINAL>{raw_response}</RESPOSTA_FINAL>"
                        emoji_logger.system_debug("‚ûï Adicionando tags <RESPOSTA_FINAL> √† resposta")
                    
                    # üö® VALIDA√á√ÉO DE SEGURAN√áA: Verificar se est√° pedindo dados proibidos
                    forbidden_terms = [
                        'cpf', 'c.p.f', 'cadastro de pessoa', 'documento',
                        'rg', 'r.g', 'identidade', 'cnh', 'c.n.h',
                        'carteira de motorista', 'carteira de identidade',
                        'dados banc√°rios', 'conta banc√°ria', 'senha',
                        'cart√£o de cr√©dito', 'dados do cart√£o'
                    ]
                    
                    response_lower = response.lower()
                    
                    # CORRE√á√ÉO: Usar regex para detectar palavras completas, n√£o substrings
                    import re
                    contains_forbidden = False
                    for term in forbidden_terms:
                        # \b marca limites de palavra para evitar falsos positivos
                        pattern = r'\b' + re.escape(term) + r'\b'
                        if re.search(pattern, response_lower):
                            contains_forbidden = True
                            break
                    
                    if contains_forbidden:
                        emoji_logger.system_warning("üö® ALERTA: Resposta cont√©m solicita√ß√£o de dados proibidos!")
                        emoji_logger.system_warning(f"Resposta original: {response}")
                        
                        # Substituir resposta por uma segura baseada no contexto
                        if multimodal_result and 'content' in multimodal_result:
                            # Se tem an√°lise de imagem, focar nisso
                            analysis = multimodal_result.get('content', '')
                            if 'conta' in analysis.lower() and 'valor' in analysis.lower():
                                response = "<RESPOSTA_FINAL>Perfeito! Vi sua conta de luz aqui. Vamos calcular quanto voc√™ pode economizar com energia solar! Me conta, esse valor est√° pesando no seu bolso?</RESPOSTA_FINAL>"
                            else:
                                response = "<RESPOSTA_FINAL>Legal! Recebi sua imagem. Para fazer uma an√°lise completa, preciso saber: qual o valor m√©dio da sua conta de luz?</RESPOSTA_FINAL>"
                        else:
                            # Resposta gen√©rica segura
                            response = "<RESPOSTA_FINAL>√ìtimo! Para eu fazer uma proposta personalizada de economia, preciso apenas saber o valor da sua conta de luz. Quanto voc√™ est√° pagando em m√©dia?</RESPOSTA_FINAL>"
                        
                        emoji_logger.system_debug(f"‚úÖ Resposta substitu√≠da por vers√£o segura: {response}")
                    
                except Exception as agent_error:
                    emoji_logger.system_error("AGENTIC SDR", f"Erro ao gerar resposta: {agent_error}")
                    # Fallback para resposta padr√£o
                    response = None
            
            # Garantir que SEMPRE temos uma resposta
            if not response or response.strip() == "":
                emoji_logger.system_warning("Nenhuma resposta gerada, usando fallback")
                # Resposta fallback baseada no contexto
                if "oi" in message.lower() or "ol√°" in message.lower() or "ola" in message.lower():
                    response = "<RESPOSTA_FINAL>Oi! Tudo bem? Sou a Helen da Solar Prime! Como posso ajudar voc√™ hoje?</RESPOSTA_FINAL>"
                elif "bom dia" in message.lower():
                    response = "<RESPOSTA_FINAL>Bom dia! Que legal voc√™ entrar em contato! Sou a Helen da Solar Prime. Em que posso ajudar?</RESPOSTA_FINAL>"
                elif "boa tarde" in message.lower():
                    response = "<RESPOSTA_FINAL>Boa tarde! Obrigada por entrar em contato com a Solar Prime! Sou a Helen, como posso ajudar?</RESPOSTA_FINAL>"
                elif "boa noite" in message.lower():
                    response = "<RESPOSTA_FINAL>Boa noite! Que bom falar com voc√™! Sou a Helen da Solar Prime. Como posso ajudar?</RESPOSTA_FINAL>"
                else:
                    response = "<RESPOSTA_FINAL>Ol√°! Sou a Helen da Solar Prime. Vi sua mensagem e adoraria ajudar! Voc√™ tem interesse em economizar na conta de luz com energia solar?</RESPOSTA_FINAL>"
            
            # 7. Atualizar estado emocional da Helen com an√°lise completa
            try:
                # Recalcular com dados completos da conversa
                current_state = current_emotional_state or "ENTUSIASMADA"
                new_emotional_state = self._update_emotional_state(
                    emotional_triggers, 
                    context_analysis,
                    current_state
                )
                
                # Salva o novo estado no banco para a pr√≥xima intera√ß√£o (usando import global)
                if conversation_id:
                    await supabase_client.update_conversation_emotional_state(
                        conversation_id,
                        new_emotional_state
                    )
            except Exception as e:
                emoji_logger.system_error("AGENTIC SDR", f"Erro ao atualizar estado emocional: {str(e)}")
                new_emotional_state = current_emotional_state or "ENTUSIASMADA"
            
            # 8. Mem√≥ria √© gerenciada automaticamente pelo Agent no AGNO v1.7.6
            # O Agent salva automaticamente as intera√ß√µes quando configurado com memory
            # N√£o precisa chamar explicitamente memory.add()
            
            # 9. Aplicar simula√ß√£o de digita√ß√£o natural
            # Garantir que response tem um valor antes de aplicar simula√ß√£o
            if response:
                response = self._apply_typing_simulation(response)
            else:
                # Fallback final se ainda n√£o houver resposta
                response = "<RESPOSTA_FINAL>Oi! üòä Sou a Helen da Solar Prime. Como posso ajudar voc√™ hoje?</RESPOSTA_FINAL>"
            
            # 10. Determinar se deve reagir ou responder citando
            result = {
                "text": response,
                "reaction": None,
                "reply_to": None
            }
            
            # L√≥gica mais natural: apenas ~10% de chance de reagir ou citar
            import random
            
            # Rea√ß√µes: apenas para mensagens muito espec√≠ficas (10% de chance)
            message_lower = message.lower().strip()
            if random.random() < 0.1:  # 10% de chance
                # Rea√ß√µes para confirma√ß√µes muito curtas
                if len(message_lower) < 10 and any(word in message_lower for word in ["ok", "blz", "üëç"]):
                    result["reaction"] = "üëç"
                # Rea√ß√µes para agradecimentos expl√≠citos
                elif len(message_lower) < 20 and any(word in message_lower for word in ["obrigado", "obrigada", "valeu"]):
                    result["reaction"] = "‚ù§Ô∏è"
                # Rea√ß√µes para risadas
                elif any(indicator in message_lower for indicator in ["kkkkk", "hahaha", "üòÇüòÇ", "ü§£ü§£"]):
                    result["reaction"] = "üòÇ"
            
            # Rea√ß√£o especial para imagens/documentos recebidos
            if media and media.get("type") in ["image", "document", "pdf"]:
                result["reaction"] = "‚úÖ"  # Confirma recebimento de m√≠dia
            
            # Cita√ß√µes: apenas em contextos muito espec√≠ficos (10% de chance)
            if message_id and random.random() < 0.1:
                # Citar quando h√° m√∫ltiplas perguntas ou contexto importante
                question_count = message.count("?")
                if question_count > 1:  # M√∫ltiplas perguntas
                    result["reply_to"] = message_id
                # Citar quando est√° respondendo a uma d√∫vida espec√≠fica ap√≥s outras mensagens
                elif conversation_id and len(messages_history or []) > 5 and "?" in message:
                    result["reply_to"] = message_id
            
            emoji_logger.agentic_response(f"Resposta gerada: {response[:100]}...")
            
            # Retornar estrutura enriquecida
            return result
            
        except Exception as e:
            emoji_logger.system_error("AGENTIC SDR", f"Erro cr√≠tico ao processar: {e}")
            # Resposta de emerg√™ncia mais natural
            emergency_responses = [
                "<RESPOSTA_FINAL>Oi! Sou a Helen da Solar Prime! Como posso ajudar voc√™ hoje com energia solar?</RESPOSTA_FINAL>",
                "<RESPOSTA_FINAL>Ol√°! Que bom voc√™ entrar em contato! Sou a Helen, especialista em energia solar. Em que posso ajudar?</RESPOSTA_FINAL>",
                "<RESPOSTA_FINAL>Oi! Tudo bem? Sou a Helen da Solar Prime! Voc√™ tem interesse em economizar na conta de luz?</RESPOSTA_FINAL>"
            ]
            import random
            # Retornar estrutura consistente mesmo em erro
            return {
                "text": random.choice(emergency_responses),
                "reaction": None,
                "reply_to": None
            }
    
    async def _personalize_team_response(
        self,
        team_response: str,
        emotional_triggers: Dict[str, Any],
        emotional_state: str = "ENTUSIASMADA"
    ) -> str:
        """Personaliza resposta do Team com toque do AGENTIC SDR"""
        
        # Adicionar personaliza√ß√£o baseada no estado emocional
        personalization_prompt = f"""
        Resposta t√©cnica: {team_response}
        
        Emo√ß√£o do lead: {emotional_triggers.get('dominant_emotion')}
        Seu estado emocional: {emotional_state}
        
        Reescreva mantendo a informa√ß√£o mas com seu toque pessoal,
        empatia e naturalidade. Mantenha breve e direto.
        """
        
        # Em AGNO v1.7.6, usar run()
        # Usar arun() para suporte ass√≠ncrono com timeout
        PERSONALIZATION_TIMEOUT = 15  # timeout menor para personaliza√ß√£o
        
        try:
            if hasattr(self.agent, 'arun'):
                result = await asyncio.wait_for(
                    self.agent.arun(personalization_prompt),
                    timeout=PERSONALIZATION_TIMEOUT
                )
            else:
                # Fallback para run() se arun() n√£o estiver dispon√≠vel
                result = await asyncio.wait_for(
                    self.agent.run(personalization_prompt),
                    timeout=PERSONALIZATION_TIMEOUT
                )
        except asyncio.TimeoutError:
            emoji_logger.system_warning(f"Timeout na personaliza√ß√£o ap√≥s {PERSONALIZATION_TIMEOUT}s, usando resposta original")
            return response  # Retorna resposta original sem personaliza√ß√£o
        except Exception as e:
            emoji_logger.system_error("Personalization", f"Erro na personaliza√ß√£o: {str(e)}, usando resposta original")
            return response  # Retorna resposta original sem personaliza√ß√£o
        
        # Extrair conte√∫do da resposta com m√∫ltiplas tentativas
        if hasattr(result, 'content') and result.content is not None:
            raw_response = result.content
        elif hasattr(result, 'text') and result.text is not None:
            raw_response = result.text
        elif hasattr(result, 'message') and result.message is not None:
            raw_response = result.message
        elif isinstance(result, dict):
            raw_response = result.get('content') or result.get('text') or result.get('message') or str(result)
        else:
            raw_response = str(result)
        
        # ‚úÖ CORRE√á√ÉO: Verificar se j√° h√° tags antes de adicionar (evita duplica√ß√£o)
        if "<RESPOSTA_FINAL>" in raw_response:
            # Resposta j√° tem tags - usar diretamente
            emoji_logger.system_debug("‚úÖ Tags <RESPOSTA_FINAL> j√° presentes na personaliza√ß√£o - usando diretamente")
            return raw_response
        else:
            # Resposta sem tags - adicionar tags para extra√ß√£o
            emoji_logger.system_debug("‚ûï Adicionando tags <RESPOSTA_FINAL> √† personaliza√ß√£o")
            return f"<RESPOSTA_FINAL>{raw_response}</RESPOSTA_FINAL>"
    
    def _update_emotional_state(
        self,
        emotional_triggers: Dict[str, Any],
        context_analysis: Dict[str, Any],
        current_state: str
    ) -> str:
        """Calcula novo estado emocional baseado na conversa - Alinhado com banco"""
        
        # Validar estado atual
        valid_states = [state.value for state in EmotionalState]
        if current_state not in valid_states:
            current_state = EmotionalState.NEUTRA.value
        
        # L√≥gica de transi√ß√£o de estados atualizada
        dominant_emotion = emotional_triggers.get("dominant_emotion")
        
        if dominant_emotion == "frustration" or dominant_emotion == "hesitation":
            # Usu√°rio com d√∫vidas ou hesita√ß√£o
            new_state = EmotionalState.DUVIDOSA.value
        
        elif dominant_emotion == "excitement" or dominant_emotion == "interest":
            # Usu√°rio animado ou interessado
            new_state = EmotionalState.ENTUSIASMADA.value
        
        elif dominant_emotion == "curiosity" or emotional_triggers.get("questions_asked", 0) > 2:
            # Usu√°rio fazendo muitas perguntas
            new_state = EmotionalState.CURIOSA.value
        
        elif context_analysis.get("decision_stage") == "decision" or \
             context_analysis.get("conversion_probability", 0) > 0.7:
            # Usu√°rio pr√≥ximo da decis√£o
            new_state = EmotionalState.CONFIANTE.value
        
        elif emotional_triggers.get("neutral_indicators", 0) > 2:
            # Conversa neutra/inicial
            new_state = EmotionalState.NEUTRA.value
        
        else:
            # Mant√©m o estado atual se v√°lido
            new_state = current_state if current_state in valid_states else EmotionalState.NEUTRA.value
        
        emoji_logger.agentic_thinking(f"Estado emocional atualizado: {new_state}",
                                     emotional_state=new_state)
        
        return new_state
    
    def _apply_typing_simulation(self, text: str) -> str:
        """Retorna o texto sem modifica√ß√£o - typing √© feito via Evolution API"""
        # IMPORTANTE: Esta fun√ß√£o N√ÉO deve modificar o texto!
        # O indicador "digitando..." √© enviado corretamente via Evolution API em webhooks.py
        # Qualquer quebra de linha aqui causa problemas no WhatsApp
        return text
    
    def get_metrics(self) -> Dict[str, Any]:
        """Retorna m√©tricas do agente"""
        return {
            "emotional_state": self.emotional_state.value,
            "cognitive_load": self.cognitive_load,
            "is_initialized": self.is_initialized
        }


# Factory function - SEMPRE cria nova inst√¢ncia para isolamento total
async def create_agentic_sdr() -> AgenticSDR:
    """Cria e inicializa nova inst√¢ncia do AGENTIC SDR para cada requisi√ß√£o"""
    agent = AgenticSDR()
    await agent.initialize()
    return agent