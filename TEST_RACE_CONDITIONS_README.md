# ðŸ§ª Testes de Race Conditions - SDR IA SolarPrime

Este documento explica como usar os testes criados para validar as correÃ§Ãµes de race conditions implementadas no sistema.

## ðŸŽ¯ Problemas Testados

Os testes foram criados para validar especificamente as correÃ§Ãµes dos seguintes problemas crÃ­ticos relatados em produÃ§Ã£o:

1. **`duplicate key value violates unique constraint 'conversations_session_id_key'`**
   - Race condition na criaÃ§Ã£o de conversas
   - Corrigido com UPSERT atÃ´mico no Supabase

2. **`WhatsAppMessage object has no field 'conversation_id'`**
   - Tentativa de acesso a campo inexistente no Pydantic
   - Corrigido com context dictionary approach

3. **Problemas de concorrÃªncia geral**
   - MÃºltiplas requisiÃ§Ãµes simultÃ¢neas
   - Timeout e performance sob carga

## ðŸ“ Arquivos de Teste

### `test_critical_race_conditions.py`
**Teste focado e rÃ¡pido** - Testa especificamente os problemas crÃ­ticos:
- âœ… Constraint violations com mesmo session_id
- âœ… Pydantic field access errors
- âœ… SessÃµes concorrentes para mesmo telefone
- âœ… Performance sob alta carga (50 requisiÃ§Ãµes)

**DuraÃ§Ã£o**: ~30 segundos

### `test_race_condition_fixes.py`
**Teste completo e extensivo** - SimulaÃ§Ã£o realÃ­stica de produÃ§Ã£o:
- âœ… Race conditions diversos
- âœ… Teste de stress prolongado
- âœ… AnÃ¡lise detalhada de performance
- âœ… RelatÃ³rio completo de mÃ©tricas

**DuraÃ§Ã£o**: 30+ segundos (configurÃ¡vel)

### `run_race_condition_tests.sh`
**Script de execuÃ§Ã£o simplificada** - Interface amigÃ¡vel para executar os testes.

## ðŸš€ Como Executar

### OpÃ§Ã£o 1: Script Automatizado (Recomendado)
```bash
# Torna o script executÃ¡vel (apenas primeira vez)
chmod +x run_race_condition_tests.sh

# Executa o script
./run_race_condition_tests.sh
```

### OpÃ§Ã£o 2: ExecuÃ§Ã£o Manual

#### PrÃ©-requisitos
```bash
# Instalar dependÃªncias
pip3 install aiohttp

# Verificar se o servidor estÃ¡ rodando
curl http://localhost:8000/health
```

#### Executar Teste CrÃ­tico (RÃ¡pido)
```bash
python3 test_critical_race_conditions.py
```

#### Executar Teste Completo
```bash
python3 test_race_condition_fixes.py
```

## ðŸ“Š InterpretaÃ§Ã£o dos Resultados

### âœ… **CorreÃ§Ãµes Funcionando** (Esperado)
```
ðŸ” CONSTRAINT VIOLATIONS 'conversations_session_id_key':
   ðŸ“Š Total de testes: 15
   âŒ Violations detectadas: 0
   âœ… SUCESSO! UPSERT atÃ´mico funcionando corretamente

ðŸ·ï¸  PYDANTIC FIELD ERRORS 'conversation_id':
   ðŸ“Š Total de testes: 10
   âŒ Errors detectados: 0
   âœ… SUCESSO! Context dict approach funcionando corretamente

ðŸŽ¯ VEREDICTO FINAL:
   âœ… TODAS AS CORREÃ‡Ã•ES FUNCIONANDO!
   ðŸš€ Sistema pronto para produÃ§Ã£o
```

### âŒ **CorreÃ§Ãµes Precisam de Ajustes**
```
ðŸ” CONSTRAINT VIOLATIONS 'conversations_session_id_key':
   ðŸ“Š Total de testes: 15
   âŒ Violations detectadas: 5
   âŒ FALHA! UPSERT precisa de mais ajustes

ðŸŽ¯ VEREDICTO FINAL:
   âŒ CORREÃ‡Ã•ES PRECISAM DE AJUSTES!
   âš ï¸  NÃ£o implantar em produÃ§Ã£o ainda
```

## ðŸ“„ RelatÃ³rios Gerados

Os testes geram relatÃ³rios JSON detalhados:

- `critical_race_conditions_report_YYYYMMDD_HHMMSS.json`
- `race_condition_test_report_YYYYMMDD_HHMMSS.json`

Esses arquivos contÃªm:
- âœ… MÃ©tricas detalhadas de performance
- âœ… Detalhes de todos os erros encontrados
- âœ… AnÃ¡lise de race conditions especÃ­ficos
- âœ… Timestamps e contexto completo

## ðŸ”§ ConfiguraÃ§Ã£o dos Testes

### Teste CrÃ­tico (`test_critical_race_conditions.py`)
```python
# ConfiguraÃ§Ãµes principais (inÃ­cio do arquivo)
CONCURRENCY_SESSIONS = 15      # RequisiÃ§Ãµes simultÃ¢neas para constraint test
PYDANTIC_TESTS = 10           # Testes de pydantic field access
MULTI_SESSION_TESTS = 8       # SessÃµes concorrentes mesmo telefone
LOAD_TEST_REQUESTS = 50       # RequisiÃ§Ãµes para teste de carga
```

### Teste Completo (`test_race_condition_fixes.py`)
```python
# ConfiguraÃ§Ãµes principais (inÃ­cio do arquivo)
CONCURRENCY_LEVEL = 10        # RequisiÃ§Ãµes simultÃ¢neas por batch
TEST_DURATION_SECONDS = 30    # DuraÃ§Ã£o total do teste
PHONE_NUMBERS = [...]         # Lista de nÃºmeros de teste
```

## ðŸ› Troubleshooting

### Problema: Servidor nÃ£o responde
```bash
# Verificar se o servidor estÃ¡ rodando
ps aux | grep uvicorn

# Iniciar o servidor
uvicorn agente.main:app --reload --host 0.0.0.0 --port 8000
```

### Problema: DependÃªncias nÃ£o instaladas
```bash
pip3 install aiohttp asyncio
```

### Problema: Timeout nos testes
- Aumente o timeout nos arquivos de teste (linha `timeout=aiohttp.ClientTimeout(total=10)`)
- Reduza a concorrÃªncia (`CONCURRENCY_LEVEL = 5`)

### Problema: Muitos erros de conexÃ£o
- Verifique se hÃ¡ rate limiting no servidor
- Reduza a frequÃªncia das requisiÃ§Ãµes
- Verifique logs do servidor para problemas

## ðŸ“ˆ Benchmarks Esperados

### Performance Normal
- âš¡ Tempo mÃ©dio de resposta: 50-200ms
- âš¡ Taxa de sucesso: >95%
- âš¡ Timeouts: <5%

### Sob Carga
- âš¡ Tempo mÃ©dio de resposta: 100-500ms
- âš¡ Taxa de sucesso: >90%
- âš¡ Timeouts: <10%

## ðŸŽ¯ PrÃ³ximos Passos ApÃ³s Testes

### Se Testes Passaram âœ…
1. Executar em ambiente de staging
2. Monitor de logs de produÃ§Ã£o
3. Deploy gradual com rollback preparado

### Se Testes Falharam âŒ
1. Analisar relatÃ³rios JSON detalhados
2. Identificar padrÃµes nos erros
3. Implementar correÃ§Ãµes adicionais
4. Re-executar testes

## ðŸ” Monitoramento ContÃ­nuo

ApÃ³s deploy em produÃ§Ã£o, monitore:
- âœ… Constraint violations em logs
- âœ… Pydantic field access errors
- âœ… Performance de response time
- âœ… Taxa de erro em webhooks

---

**ðŸ“ž Suporte**: Em caso de problemas, analise os logs detalhados e relatÃ³rios JSON gerados pelos testes.